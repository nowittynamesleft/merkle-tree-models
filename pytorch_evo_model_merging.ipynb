{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwPU6S1ZdUN8",
    "outputId": "fb430210-3e7d-42eb-ab26-0db9538130a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data information\n",
      "====================\n",
      "#samples=1797, image_size=torch.Size([64])\n",
      "#odd_num_images=906\n",
      "#even_num_images=891\n",
      "num_params=19210\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import asyncio\n",
    "from sklearn import datasets\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ['ENABLE_ICICLE_GPU'] = 'true'\n",
    "os.environ['RUST_BACKTRACE']='full'\n",
    "\n",
    "# check if notebook is in colab\n",
    "try:\n",
    "    # install ezkl\n",
    "    import google.colab\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
    "\n",
    "# rely on local installation of ezkl if the notebook is not in colab\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import ezkl\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Task definition\n",
    "\n",
    "print('Data information')\n",
    "print('=' * 20)\n",
    "\n",
    "images, labels = datasets.load_digits(return_X_y=True)\n",
    "images = torch.tensor(images, dtype=torch.float32)\n",
    "labels = torch.tensor(labels, dtype=torch.int64)\n",
    "print(f'#samples={len(images)}, image_size={images[0].shape}')\n",
    "\n",
    "mask = labels % 2 == 1\n",
    "odd_num_images, odd_num_labels = images[mask], labels[mask]\n",
    "print(f'#odd_num_images={len(odd_num_images)}')\n",
    "\n",
    "mask = labels % 2 == 0\n",
    "even_num_images, even_num_labels = images[mask], labels[mask]\n",
    "print(f'#even_num_images={len(even_num_images)}')\n",
    "\n",
    "# Neural network definition\n",
    "hidden_dim = 256\n",
    "input_dim = 64\n",
    "output_dim = 10\n",
    "num_params = (1 + input_dim) * hidden_dim + (1 + hidden_dim) * output_dim\n",
    "print(f'num_params={num_params}')\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_loss(model, data, labels):\n",
    "    logits = model(data)\n",
    "    log_probs = F.log_softmax(logits, dim=1)\n",
    "    true_log_probs = log_probs.gather(1, labels.view(-1, 1))\n",
    "    return -true_log_probs.mean()\n",
    "\n",
    "\n",
    "def get_grad(model, data, labels):\n",
    "    model.zero_grad()\n",
    "    loss = get_loss(model, data, labels)\n",
    "    loss.backward()\n",
    "    return model.parameters()\n",
    "\n",
    "\n",
    "def get_acc(logits, labels):\n",
    "    predicted_labels = logits.argmax(dim=1)\n",
    "    return (predicted_labels == labels).float().mean().item()\n",
    "\n",
    "\n",
    "def train(model, x, y, lr=0.003, num_epochs=10):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for _ in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = get_loss(model, x, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "# Test\n",
    "mlp = MLP()\n",
    "rand_params = torch.randn(num_params) * 0.01\n",
    "mlp.fc1.weight.data = rand_params[:hidden_dim * input_dim].view(hidden_dim, input_dim)\n",
    "mlp.fc1.bias.data = rand_params[hidden_dim * input_dim:hidden_dim * input_dim + hidden_dim]\n",
    "mlp.fc2.weight.data = rand_params[-(output_dim * hidden_dim + output_dim):-output_dim].view(output_dim, hidden_dim)\n",
    "mlp.fc2.bias.data = rand_params[-output_dim:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmazpzbAe5rr",
    "outputId": "e37ca022-ef6e-4c0a-b166-f78b9e2cca15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 64])\n",
      "Random MLP: loss=2.3118, acc=0.06\n",
      "mlp1 acc@d_odd=0.94\n",
      "mlp1 acc@d_even=0.00\n",
      "mlp1 acc@d0-9=0.47\n",
      "----------\n",
      "mlp2 acc@d_odd=0.00\n",
      "mlp2 acc@d_even=0.98\n",
      "mlp2 acc@d0-9=0.48\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "logits = mlp(images)\n",
    "loss = get_loss(mlp, images, labels)\n",
    "acc = get_acc(logits, labels)\n",
    "print(f'Random MLP: loss={loss.item():.4f}, acc={acc:.2f}')\n",
    "\n",
    "# Train 2 seed MLPs\n",
    "mlp1 = MLP()\n",
    "mlp2 = MLP()\n",
    "\n",
    "mlp1 = train(mlp1, odd_num_images, odd_num_labels)\n",
    "mlp2 = train(mlp2, even_num_images, even_num_labels)\n",
    "\n",
    "models = [mlp1, mlp2]\n",
    "model_names = ['mlp1', 'mlp2']\n",
    "for model, model_name in zip(models, model_names):\n",
    "    for x, y, name in zip([odd_num_images, even_num_images, images], [odd_num_labels, even_num_labels, labels], ['d_odd', 'd_even', 'd0-9']):\n",
    "        logits = model(x)\n",
    "        acc = get_acc(logits, y)\n",
    "        print(f'{model_name} acc@{name}={acc:.2f}')\n",
    "    print('-' * 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "6EVdBmBnfA2m",
    "outputId": "641b1c70-6d5e-418c-d1b0-0f9ac7a26e48"
   },
   "outputs": [],
   "source": [
    "# Evolutionary algorithm merging class and function definitions\n",
    "#n_iter = 1000\n",
    "#n_iter = 10\n",
    "#n_iter = 20\n",
    "n_iter = 5\n",
    "mutation_std = 0.01\n",
    "#pop_size = 512\n",
    "#num_elite = 4\n",
    "#pop_size = 10\n",
    "\n",
    "pop_size = 10\n",
    "num_elite = 4\n",
    "seed = 42\n",
    "\n",
    "class Slerp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Slerp, self).__init__()\n",
    "\n",
    "    '''\n",
    "    def forward(self, val, x, y):\n",
    "      norm_x = F.normalize(x, dim=-1)\n",
    "      norm_y = F.normalize(y, dim=-1)\n",
    "      dot = torch.sum(norm_x * norm_y, dim=-1, keepdim=True)\n",
    "      omega = torch.acos(torch.clamp(dot, -1.0, 1.0))\n",
    "      sin_omega = torch.sin(omega)\n",
    "      scale_x = torch.sin((1.0 - val) * omega) / sin_omega\n",
    "      scale_y = torch.sin(val * omega) / sin_omega\n",
    "      lin_scale_x = 1.0 - val\n",
    "      lin_scale_y = val\n",
    "      return torch.where(sin_omega > 1e-6, scale_x * x + scale_y * y, lin_scale_x * x + lin_scale_y * y)\n",
    "    '''\n",
    "    def forward(self, val, x, y):\n",
    "        return val*x + (1-val)*y\n",
    "\n",
    "class Mutate(nn.Module):\n",
    "    def __init__(self, mutation_std):\n",
    "        super(Mutate, self).__init__()\n",
    "        self.mutation_std = mutation_std\n",
    "\n",
    "    def forward(self, rand_num, gene):\n",
    "        noise = rand_num*self.mutation_std\n",
    "        return gene + noise\n",
    "\n",
    "slerp = Slerp()\n",
    "mutate = Mutate(mutation_std)\n",
    "RUN_FOLDER = './test_merge_dir/'\n",
    "\n",
    "from pathlib import Path\n",
    "Path(RUN_FOLDER).mkdir(parents=True, exist_ok=True) # create directory and any intermediate directories\n",
    "\n",
    "#import ipdb\n",
    "'''\n",
    "def crossover(parents):\n",
    "    w = torch.rand(1)\n",
    "    return slerp(w, parents[0], parents[1])\n",
    "'''\n",
    "\n",
    "'''    \n",
    "async def calibrate_mutate(rand_num, model, mutate_fn):\n",
    "    model_path = os.path.join(RUN_FOLDER + 'mutate.onnx')\n",
    "    compiled_model_path = os.path.join(RUN_FOLDER + 'mutate_network.compiled')\n",
    "    pk_path = os.path.join(RUN_FOLDER + 'mutate_test.pk')\n",
    "    vk_path = os.path.join(RUN_FOLDER + 'mutate_test.vk')\n",
    "    settings_path = os.path.join(RUN_FOLDER + 'mutate_settings.json')\n",
    "    \n",
    "    witness_path = os.path.join(RUN_FOLDER + 'mutate_witness.json')\n",
    "    data_path = os.path.join(RUN_FOLDER + 'mutate_input.json')\n",
    "    \n",
    "    torch.onnx.export(\n",
    "        mutate_fn,                       # the model/module to be exported\n",
    "        (rand_num, model),                 # example inputs\n",
    "        model_path,                # the file name to save the ONNX model\n",
    "        export_params=True,          # store the trained parameter weights inside the model file\n",
    "        opset_version=11,            # the ONNX version to export the model to\n",
    "        do_constant_folding=True,    # whether to execute constant folding for optimization\n",
    "        input_names=['rand_num', 'model'],  # input names\n",
    "        output_names=['mutated_weights']        # output name\n",
    "    )\n",
    "    \n",
    "    py_run_args = ezkl.PyRunArgs()\n",
    "    py_run_args.input_visibility = \"public\"\n",
    "    py_run_args.output_visibility = \"public\"\n",
    "    # assuming params for mutate are none (model params are considered inputs in this case, right?)\n",
    "    py_run_args.param_visibility = \"fixed\" # \"fixed\" for params means that the committed to params are used for all proofs\n",
    "\n",
    "    res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "\n",
    "    assert res == True\n",
    "\n",
    "    data = dict(input_data = [rand_num.detach().numpy().reshape(-1).tolist(), \n",
    "                              torch.rand(*model.shape).detach().numpy().reshape(-1).tolist()])\n",
    "    cal_path = os.path.join(RUN_FOLDER + \"mutate_calibration.json\")\n",
    "\n",
    "    json.dump(data, open(cal_path, 'w'))\n",
    "\n",
    "    await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
    "\n",
    "    res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "    assert res == True\n",
    "\n",
    "    # srs path\n",
    "    res = ezkl.get_srs( settings_path)\n",
    "\n",
    "    # HERE WE SETUP THE CIRCUIT PARAMS\n",
    "    # WE GOT KEYS\n",
    "    # WE GOT CIRCUIT PARAMETERS\n",
    "    # EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
    "    \n",
    "    res = ezkl.setup(\n",
    "            compiled_model_path,\n",
    "            vk_path,\n",
    "            pk_path,\n",
    "        )\n",
    "    \n",
    "    assert res == True\n",
    "\n",
    "async def calibrate_circuit(val, parent_1, parent_2):\n",
    "    model_path = os.path.join(RUN_FOLDER + 'slerp.onnx')\n",
    "    compiled_model_path = os.path.join(RUN_FOLDER + 'network.compiled')\n",
    "    pk_path = os.path.join(RUN_FOLDER + 'merge_test.pk')\n",
    "    vk_path = os.path.join(RUN_FOLDER + 'merge_test.vk')\n",
    "    settings_path = os.path.join(RUN_FOLDER + 'settings.json')\n",
    "    \n",
    "    witness_path = os.path.join(RUN_FOLDER + 'witness.json')\n",
    "    data_path = os.path.join(RUN_FOLDER + 'slerp_input.json')\n",
    "    torch.onnx.export(\n",
    "        slerp,                       # the model/module to be exported\n",
    "        (val, parent_1, parent_2),                 # example inputs\n",
    "        model_path,                # the file name to save the ONNX model\n",
    "        export_params=True,          # store the trained parameter weights inside the model file\n",
    "        opset_version=11,            # the ONNX version to export the model to\n",
    "        do_constant_folding=True,    # whether to execute constant folding for optimization\n",
    "        input_names=['val', 'parent_1', 'parent_2'],  # input names\n",
    "        output_names=['merged_weights']        # output name\n",
    "        #dynamic_axes={'x': {0: 'batch_size'}, 'y': {0: 'batch_size'}, 'result': {0: 'batch_size'}}  # no dynamic axis for merging\n",
    "    )\n",
    "\n",
    "    py_run_args = ezkl.PyRunArgs()\n",
    "    py_run_args.input_visibility = \"public\"\n",
    "    py_run_args.output_visibility = \"public\"\n",
    "    # assuming params for slerp are none (model params are considered inputs in this case, right?)\n",
    "    py_run_args.param_visibility = \"fixed\" # \"fixed\" for params means that the committed to params are used for all proofs\n",
    "\n",
    "    res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "    assert res == True\n",
    "    \n",
    "    data = dict(input_data = [[val.item()], \n",
    "                              torch.rand(*parent_1.shape).detach().numpy().reshape(-1).tolist(), \n",
    "                              torch.rand(*parent_2.shape).detach().numpy().reshape(-1).tolist()])\n",
    "    cal_path = os.path.join(RUN_FOLDER + \"calibration.json\")\n",
    "\n",
    "    json.dump(data, open(cal_path, 'w'))\n",
    "\n",
    "    await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
    "    #await ezkl.calibrate_settings(cal_path, model_path, settings_path)\n",
    "\n",
    "    res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "    assert res == True\n",
    "\n",
    "    # srs path\n",
    "    res = ezkl.get_srs( settings_path)\n",
    "\n",
    "    # HERE WE SETUP THE CIRCUIT PARAMS\n",
    "    # WE GOT KEYS\n",
    "    # WE GOT CIRCUIT PARAMETERS\n",
    "    # EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
    "    \n",
    "    res = ezkl.setup(\n",
    "            compiled_model_path,\n",
    "            vk_path,\n",
    "            pk_path,\n",
    "        )\n",
    "    \n",
    "    assert res == True\n",
    "'''\n",
    "\n",
    "async def calibrate_operation(op_name, example_inputs, calibration_inputs, input_names, operation_fn, output_names):\n",
    "    model_path = os.path.join(RUN_FOLDER + op_name + '.onnx')\n",
    "    compiled_model_path = os.path.join(RUN_FOLDER + op_name + '_network.compiled')\n",
    "    pk_path = os.path.join(RUN_FOLDER + op_name + '_test.pk')\n",
    "    vk_path = os.path.join(RUN_FOLDER + op_name + '_test.vk')\n",
    "    settings_path = os.path.join(RUN_FOLDER + op_name + '_settings.json')\n",
    "    witness_path = os.path.join(RUN_FOLDER + op_name + '_calibration_witness.json')\n",
    "    data_path = os.path.join(RUN_FOLDER + op_name + '_calibration_input.json')\n",
    "\n",
    "    #import ipdb; ipdb.set_trace()\n",
    "    torch.onnx.export(\n",
    "        operation_fn,                       # the model/module to be exported\n",
    "        example_inputs,                 # example inputs\n",
    "        model_path,                # the file name to save the ONNX model\n",
    "        export_params=True,          # store the trained parameter weights inside the model file\n",
    "        opset_version=11,            # the ONNX version to export the model to\n",
    "        do_constant_folding=True,    # whether to execute constant folding for optimization\n",
    "        input_names=input_names,  # input names\n",
    "        output_names=output_names        # output name\n",
    "    )\n",
    "    \n",
    "    py_run_args = ezkl.PyRunArgs()\n",
    "    py_run_args.input_visibility = \"public\"\n",
    "    py_run_args.output_visibility = \"public\"\n",
    "    py_run_args.param_visibility = \"fixed\" # \"fixed\" for params means that the committed to params are used for all proofs\n",
    "\n",
    "    res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "\n",
    "    assert res == True\n",
    "\n",
    "    #data = dict(input_data = [rand_num.detach().numpy().reshape(-1).tolist(), \n",
    "    #                          torch.rand(*model.shape).detach().numpy().reshape(-1).tolist()])\n",
    "    data = dict(input_data = calibration_inputs)\n",
    "    cal_path = os.path.join(RUN_FOLDER + op_name + \"_calibration.json\")\n",
    "\n",
    "    json.dump(data, open(cal_path, 'w'))\n",
    "\n",
    "    await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
    "\n",
    "    res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "    assert res == True\n",
    "\n",
    "    # srs path\n",
    "    res = ezkl.get_srs( settings_path)\n",
    "\n",
    "    # HERE WE SETUP THE CIRCUIT PARAMS\n",
    "    # WE GOT KEYS\n",
    "    # WE GOT CIRCUIT PARAMETERS\n",
    "    # EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
    "    \n",
    "    res = ezkl.setup(\n",
    "            compiled_model_path,\n",
    "            vk_path,\n",
    "            pk_path,\n",
    "        )\n",
    "    \n",
    "    assert res == True\n",
    "\n",
    "\n",
    "async def prove_operation(op_name, operation_save_name, inputs):\n",
    "    model_path = os.path.join(RUN_FOLDER + op_name + '.onnx')\n",
    "    compiled_model_path = os.path.join(RUN_FOLDER + op_name + '_network.compiled')\n",
    "    pk_path = os.path.join(RUN_FOLDER + op_name + '_test.pk')\n",
    "    vk_path = os.path.join(RUN_FOLDER + op_name + '_test.vk')\n",
    "    settings_path = os.path.join(RUN_FOLDER + op_name + '_settings.json')\n",
    "\n",
    "    witness_path = os.path.join(RUN_FOLDER + op_name + '_input_' + operation_save_name + 'witness.json')\n",
    "    data_path = os.path.join(RUN_FOLDER + op_name + '_input_' + operation_save_name + '.json')\n",
    "\n",
    "    # now generate the witness file\n",
    "\n",
    "    data = dict(input_data = inputs)\n",
    "    with open(data_path, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "    res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "    assert os.path.isfile(witness_path)\n",
    "\n",
    "    assert os.path.isfile(vk_path)\n",
    "    assert os.path.isfile(pk_path)\n",
    "    assert os.path.isfile(settings_path)\n",
    "\n",
    "    # GENERATE A PROOF\n",
    "\n",
    "    proof_path = os.path.join(RUN_FOLDER + operation_save_name + '_test.pf')\n",
    "    '''\n",
    "    proof = ezkl.prove(\n",
    "            witness_path,\n",
    "            compiled_model_path,\n",
    "            pk_path,\n",
    "            proof_path,\n",
    "\n",
    "            \"single\",\n",
    "        )\n",
    "    '''\n",
    "    proof = ezkl.prove(\n",
    "            witness_path,\n",
    "            compiled_model_path,\n",
    "            pk_path,\n",
    "            proof_path,\n",
    "\n",
    "            \"for-aggr\",\n",
    "        )\n",
    "    assert os.path.isfile(proof_path)\n",
    "    return proof\n",
    "\n",
    "async def zk_prove_merge(val, merge_idx, parent_1, parent_2, iteration, parent_ind_1, parent_ind_2):\n",
    "    merge_id = 'iter_' + str(iteration) + '_merge_idx_' + str(merge_idx) + '_p1_' + str(parent_ind_1.item()) + '_p2_' + str(parent_ind_2.item())\n",
    "    model_path = os.path.join(RUN_FOLDER + 'slerp.onnx')\n",
    "    compiled_model_path = os.path.join(RUN_FOLDER + 'network.compiled')\n",
    "    #pk_path = os.path.join(RUN_FOLDER + merge_id + '_test.pk')\n",
    "    #vk_path = os.path.join(RUN_FOLDER + merge_id + '_test.vk')\n",
    "    pk_path = os.path.join(RUN_FOLDER + 'merge_test.pk')\n",
    "    vk_path = os.path.join(RUN_FOLDER + 'merge_test.vk')\n",
    "    settings_path = os.path.join(RUN_FOLDER + 'settings.json')\n",
    "\n",
    "    witness_path = os.path.join(RUN_FOLDER + 'witness.json')\n",
    "    data_path = os.path.join(RUN_FOLDER + 'slerp_input_' + merge_id + '.json')\n",
    "\n",
    "    # now generate the witness file\n",
    "\n",
    "    data = dict(input_data = [[val.item()], \n",
    "                              parent_1.detach().numpy().reshape(-1).tolist(), \n",
    "                              parent_2.detach().numpy().reshape(-1).tolist()])\n",
    "    with open(data_path, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "    res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "    assert os.path.isfile(witness_path)\n",
    "\n",
    "\n",
    "    assert os.path.isfile(vk_path)\n",
    "    assert os.path.isfile(pk_path)\n",
    "    assert os.path.isfile(settings_path)\n",
    "\n",
    "    # GENERATE A PROOF\n",
    "\n",
    "    proof_path = os.path.join(RUN_FOLDER + merge_id + '_test.pf')\n",
    "    '''\n",
    "    proof = ezkl.prove(\n",
    "            witness_path,\n",
    "            compiled_model_path,\n",
    "            pk_path,\n",
    "            proof_path,\n",
    "\n",
    "            \"single\",\n",
    "        )\n",
    "    '''\n",
    "    proof = ezkl.prove(\n",
    "            witness_path,\n",
    "            compiled_model_path,\n",
    "            pk_path,\n",
    "            proof_path,\n",
    "\n",
    "            \"for-aggr\",\n",
    "        )\n",
    "    assert os.path.isfile(proof_path)\n",
    "    return proof\n",
    "\n",
    "\n",
    "def crossover(parents, iteration, parent_inds, merge_idx):\n",
    "    val = torch.rand(1)\n",
    "    loop = asyncio.get_event_loop()\n",
    "    #proof = loop.run_until_complete(zk_prove_merge(val, merge_idx, parents[0], parents[1], iteration, parent_inds[0], parent_inds[1]))\n",
    "    parent_1, parent_2 = parents\n",
    "    parent_ind_1, parent_ind_2 = parent_inds\n",
    "    merge_id = 'iter_' + str(iteration) + '_merge_idx_' + str(merge_idx) + '_p1_' + str(parent_ind_1.item()) + '_p2_' + str(parent_ind_2.item())\n",
    "    inputs = [[val.item()], \n",
    "                              parent_1.detach().numpy().reshape(-1).tolist(), \n",
    "                              parent_2.detach().numpy().reshape(-1).tolist()]\n",
    "    proof = loop.run_until_complete(prove_operation('merge', merge_id, inputs))\n",
    "    #proof = None\n",
    "    result = slerp(val, parents[0], parents[1])\n",
    "    return result, proof\n",
    "\n",
    "'''\n",
    "def mutate(gene, rand_num):\n",
    "    noise = rand_num * mutation_std\n",
    "    return gene + noise\n",
    "'''\n",
    "\n",
    "async def prove_mutate(rand_num, model, merge_idx, iteration):\n",
    "    merge_id = 'iter_' + str(iteration) + '_merge_idx_' + str(merge_idx) + '_mutate'\n",
    "    model_path = os.path.join(RUN_FOLDER + 'mutate.onnx')\n",
    "    compiled_model_path = os.path.join(RUN_FOLDER + 'mutate_network.compiled')\n",
    "    #pk_path = os.path.join(RUN_FOLDER + merge_id + '_mutate_test.pk')\n",
    "    #vk_path = os.path.join(RUN_FOLDER + merge_id + '_mutate_test.vk')\n",
    "    pk_path = os.path.join(RUN_FOLDER + 'mutate_test.pk') # these can be the same as the calibrated ones?\n",
    "    vk_path = os.path.join(RUN_FOLDER + 'mutate_test.vk')\n",
    "    settings_path = os.path.join(RUN_FOLDER + 'mutate_settings.json')\n",
    "    \n",
    "    witness_path = os.path.join(RUN_FOLDER + 'mutate_witness.json')\n",
    "    data_path = os.path.join(RUN_FOLDER + merge_id + 'mutate_input.json')\n",
    "\n",
    "    # now generate the witness file\n",
    "\n",
    "    data = dict(input_data = [rand_num.detach().numpy().reshape(-1).tolist(), \n",
    "                              model.detach().numpy().reshape(-1).tolist()])\n",
    "    with open(data_path, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "    res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "    assert os.path.isfile(witness_path)\n",
    "\n",
    "    '''\n",
    "    # HERE WE SETUP THE CIRCUIT PARAMS\n",
    "    # WE GOT KEYS\n",
    "    # WE GOT CIRCUIT PARAMETERS\n",
    "    # EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
    "    \n",
    "    res = ezkl.setup(\n",
    "            compiled_model_path,\n",
    "            vk_path,\n",
    "            pk_path,\n",
    "        )\n",
    "    '''\n",
    "\n",
    "    assert os.path.isfile(vk_path)\n",
    "    assert os.path.isfile(pk_path)\n",
    "    assert os.path.isfile(settings_path)\n",
    "\n",
    "    # GENERATE A PROOF\n",
    "\n",
    "    proof_path = os.path.join(RUN_FOLDER + merge_id + '_test.pf')\n",
    "\n",
    "    '''\n",
    "    proof = ezkl.prove(\n",
    "            witness_path,\n",
    "            compiled_model_path,\n",
    "            pk_path,\n",
    "            proof_path,\n",
    "            \"single\",\n",
    "        )\n",
    "    '''\n",
    "    proof = ezkl.prove(\n",
    "            witness_path,\n",
    "            compiled_model_path,\n",
    "            pk_path,\n",
    "            proof_path,\n",
    "            \"for-aggr\",\n",
    "        )\n",
    "    \n",
    "    assert os.path.isfile(proof_path)\n",
    "    return proof\n",
    "\n",
    "def ask(elite_solutions, iteration, mutate_fn):\n",
    "    parents_indices = torch.randint(0, elite_solutions.shape[0], (pop_size * 2,))\n",
    "    #ipdb.set_trace()\n",
    "    parents = elite_solutions[parents_indices].view(pop_size, 2, -1)\n",
    "    p_inds = parents_indices.view(pop_size, 2)\n",
    "    #population = torch.stack([crossover(p, iteration, p_inds[i]) for i, p in enumerate(parents)])\n",
    "    pop_list = []\n",
    "    proof_list = []\n",
    "    for merge_idx, p in enumerate(parents):\n",
    "        merged_model, proof = crossover(p, iteration, p_inds[merge_idx], merge_idx)\n",
    "        pop_list.append(merged_model)\n",
    "        proof_list.append(proof)\n",
    "    population = torch.stack(pop_list)\n",
    "    pop = []\n",
    "    mutate_proof_list = []\n",
    "    loop = asyncio.get_event_loop()\n",
    "    for merge_idx, g in enumerate(population):\n",
    "        rand_num = torch.randn(g.shape)\n",
    "        proof = loop.run_until_complete(prove_mutate(rand_num, g, merge_idx, iteration))\n",
    "        pop.append([mutate(rand_num, g) for g in population])\n",
    "        mutate_proof_list.append(proof)\n",
    "        \n",
    "    return population, proof_list, mutate_proof_list, p_inds\n",
    "\n",
    "def get_flat_params(model):\n",
    "    return torch.concatenate([p.view(-1) for p in model.parameters()])\n",
    "\n",
    "def tell(population, scores, proofs):\n",
    "    top_scores, top_indices = scores.topk(num_elite)\n",
    "    new_elites = population[top_indices]\n",
    "    new_elites_proofs = [proofs[idx] for idx in top_indices]\n",
    "    new_elites[-1] = get_flat_params(mlp1)\n",
    "    new_elites[-2] = get_flat_params(mlp2)\n",
    "    return new_elites, new_elites_proofs, top_indices\n",
    "\n",
    "def reroll_params(flat_params):\n",
    "    model = MLP()\n",
    "    \n",
    "    # Load the model's parameters from the flattened params vector, reshaping the weights\n",
    "    model.fc1.weight.data = flat_params[:hidden_dim * input_dim].view(hidden_dim, input_dim)\n",
    "\n",
    "    model.fc1.bias.data = flat_params[(hidden_dim * input_dim):(hidden_dim * input_dim + hidden_dim)]\n",
    "\n",
    "    model.fc2.weight.data = flat_params[-(output_dim * hidden_dim + output_dim):-output_dim].view(output_dim, hidden_dim)\n",
    "\n",
    "    model.fc2.bias.data = flat_params[-output_dim:]\n",
    "    return model\n",
    "\n",
    "def eval_params(params, x, y):\n",
    "    model = reroll_params(params)\n",
    "\n",
    "    # Reshape the input data to match the expected input size of the model\n",
    "    x_reshaped = x.view(-1, input_dim)  # Reshape to [batch_size, input_dim]\n",
    "\n",
    "    logits = model(x_reshaped)  # Pass the reshaped input to the model\n",
    "    return get_acc(logits, y)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "6EVdBmBnfA2m",
    "outputId": "641b1c70-6d5e-418c-d1b0-0f9ac7a26e48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 2 columns for non-linearity table.\n",
      "Using 3 columns for non-linearity table.\n",
      "Using 3 columns for non-linearity table.\n",
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+--------------------+------------------+---------------+-----------------+----------------+------------------+---------------+---------------+---------------------+--------------------+------------------------+\n",
      "| mean_error         | median_error     | max_error     | min_error       | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error  | mean_percent_error | mean_abs_percent_error |\n",
      "+--------------------+------------------+---------------+-----------------+----------------+------------------+---------------+---------------+---------------------+--------------------+------------------------+\n",
      "| -0.000000083151484 | -0.0000029802322 | 0.00006145239 | -0.000060737133 | 0.00002204093  | 0.0000029802322  | 0.00006145239 | 0             | 0.00000000069010536 | 0.00000010636553   | 0.000062774285         |\n",
      "+--------------------+------------------+---------------+-----------------+----------------+------------------+---------------+---------------+---------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration duration: 12.032300472259521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 10) ------------->\n",
      "\n",
      "+-------------------+----------------+--------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error        | median_error   | max_error    | min_error      | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+-------------------+----------------+--------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| -0.00000049366815 | 0.000051617622 | 0.0000872314 | -0.00008928776 | 0.00003106617  | 0.000051617622   | 0.00008928776 | 0             | 0.000000001321525  | -0.00016646355     | 0.0004430804           |\n",
      "+-------------------+----------------+--------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration duration: 12.032300472259521\n"
     ]
    }
   ],
   "source": [
    "# Initialize the elites with seed models\n",
    "mlp1_param = torch.concatenate([mlp1.state_dict()['fc1.weight'].view(-1), mlp1.state_dict()['fc1.bias'].view(-1), mlp1.state_dict()['fc2.weight'].view(-1), mlp1.state_dict()['fc2.bias'].view(-1)])\n",
    "mlp2_param = torch.concatenate([mlp2.state_dict()['fc1.weight'].view(-1), mlp2.state_dict()['fc1.bias'].view(-1), mlp2.state_dict()['fc2.weight'].view(-1), mlp2.state_dict()['fc2.bias'].view(-1)])\n",
    "elites = torch.stack([mlp1_param, mlp2_param])\n",
    "#elites = elites[torch.randint(0, 2, (num_elite,))]\n",
    "\n",
    "# calibrate circuit\n",
    "val = torch.rand(1)\n",
    "loop = asyncio.get_event_loop()\n",
    "calibrate_start = time.time()\n",
    "#verified = loop.run_until_complete(calibrate_circuit(val, mlp1_param, mlp2_param))\n",
    "\n",
    "op_name = 'merge'\n",
    "example_inputs = (val, mlp1_param, mlp2_param)\n",
    "calibration_inputs = [[val.item()], \n",
    "                              torch.rand(*mlp1_param.shape).detach().numpy().reshape(-1).tolist(), \n",
    "                              torch.rand(*mlp2_param.shape).detach().numpy().reshape(-1).tolist()]\n",
    "input_names = ['val', 'parent_1', 'parent_2']  # input names\n",
    "operation_fn = slerp\n",
    "output_names = ['merged_weights']        # output name\n",
    "\n",
    "loop.run_until_complete(calibrate_operation(op_name, example_inputs, calibration_inputs, input_names, operation_fn, output_names))\n",
    "\n",
    "calibrate_end = time.time()\n",
    "calibration_duration = calibrate_end - calibrate_start\n",
    "print('Calibration duration: ' + str(calibration_duration))\n",
    "\n",
    "# mutate calibration\n",
    "\n",
    "mutate_calibrate_start = time.time()\n",
    "rand_num = torch.randn(mlp1_param.shape)\n",
    "\n",
    "#verified = loop.run_until_complete(calibrate_mutate(rand_num, mlp1_param, mutate))\n",
    "op_name = 'mutate'\n",
    "example_inputs = (rand_num, mlp1_param)\n",
    "calibration_inputs = [rand_num.detach().numpy().reshape(-1).tolist(), \n",
    "                              torch.rand(*mlp1_param.shape).detach().numpy().reshape(-1).tolist()]\n",
    "input_names = ['rand_num', 'model']\n",
    "operation_fn = mutate\n",
    "output_names = ['mutated_weights']\n",
    "loop.run_until_complete(calibrate_operation(op_name, example_inputs, calibration_inputs, input_names, operation_fn, output_names))\n",
    "\n",
    "mutate_calibrate_end = time.time()\n",
    "mutate_calibration_duration = mutate_calibrate_end - mutate_calibrate_start\n",
    "print('Calibration duration: ' + str(calibration_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "6EVdBmBnfA2m",
    "outputId": "641b1c70-6d5e-418c-d1b0-0f9ac7a26e48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 5/5 [03:57<00:00, 47.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evolutionary model merging with proof generation duration: 237.7396683692932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Optimization loop\n",
    "acc_max = []\n",
    "merge_idx_and_p_inds = []\n",
    "\n",
    "top_model_history = [] # list of parents of top model\n",
    "all_model_histories = [] # list of lists of parents of current population of models\n",
    "\n",
    "start_time = time.time()\n",
    "for i in tqdm(range(n_iter)):\n",
    "    population, proofs, mutate_proofs, p_inds = ask(elites, i, mutate)\n",
    "    p_inds_w_merge_idx = torch.concatenate([torch.arange(pop_size).reshape(-1,1), p_inds], dim=1) # concatenated iteration number and all parent indices\n",
    "    merge_idx_and_p_inds.append(p_inds_w_merge_idx)\n",
    "    #print(population.shape)\n",
    "    scores = torch.tensor([eval_params(p, images, labels) for p in population])\n",
    "    #print('score values')\n",
    "    #print(scores)\n",
    "    #elites = tell(elites, scores)\n",
    "    elites, new_elites_proofs, top_inds = tell(population, scores, proofs)\n",
    "    acc_max.append(scores.max().item())\n",
    "\n",
    "merge_idx_and_p_inds = torch.stack(merge_idx_and_p_inds)\n",
    "best_ind = top_inds[0]\n",
    "\n",
    "end_time = time.time()\n",
    "duration = end_time - start_time\n",
    "print('Evolutionary model merging with proof generation duration: ' + str(duration))\n",
    "# Plot the results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
    "\n",
    "ax = axes[0]\n",
    "ax.plot(np.maximum.accumulate(acc_max))\n",
    "ax.set_title('Best model performance')\n",
    "ax = axes[1]\n",
    "ax.plot(acc_max)\n",
    "ax.set_title('Max accuracy per generation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0, 1, 1],\n",
      "         [1, 1, 0],\n",
      "         [2, 0, 0],\n",
      "         [3, 0, 1],\n",
      "         [4, 0, 0],\n",
      "         [5, 0, 0],\n",
      "         [6, 1, 1],\n",
      "         [7, 0, 0],\n",
      "         [8, 0, 0],\n",
      "         [9, 0, 0]],\n",
      "\n",
      "        [[0, 2, 0],\n",
      "         [1, 1, 1],\n",
      "         [2, 2, 2],\n",
      "         [3, 1, 1],\n",
      "         [4, 1, 0],\n",
      "         [5, 1, 1],\n",
      "         [6, 1, 0],\n",
      "         [7, 3, 2],\n",
      "         [8, 0, 3],\n",
      "         [9, 3, 2]],\n",
      "\n",
      "        [[0, 3, 0],\n",
      "         [1, 2, 1],\n",
      "         [2, 1, 0],\n",
      "         [3, 2, 2],\n",
      "         [4, 2, 2],\n",
      "         [5, 3, 0],\n",
      "         [6, 0, 3],\n",
      "         [7, 2, 1],\n",
      "         [8, 0, 3],\n",
      "         [9, 0, 0]],\n",
      "\n",
      "        [[0, 1, 1],\n",
      "         [1, 2, 3],\n",
      "         [2, 0, 1],\n",
      "         [3, 2, 1],\n",
      "         [4, 1, 2],\n",
      "         [5, 2, 3],\n",
      "         [6, 1, 1],\n",
      "         [7, 2, 2],\n",
      "         [8, 1, 0],\n",
      "         [9, 0, 3]],\n",
      "\n",
      "        [[0, 2, 3],\n",
      "         [1, 3, 2],\n",
      "         [2, 3, 3],\n",
      "         [3, 0, 2],\n",
      "         [4, 0, 3],\n",
      "         [5, 2, 3],\n",
      "         [6, 0, 3],\n",
      "         [7, 1, 0],\n",
      "         [8, 3, 3],\n",
      "         [9, 1, 3]]])\n"
     ]
    }
   ],
   "source": [
    "print(merge_idx_and_p_inds)\n",
    "async def verify_proof(op_name, operation_save_name):\n",
    "    proof_path = os.path.join(RUN_FOLDER + operation_save_name + '_test.pf')\n",
    "    settings_path = os.path.join(RUN_FOLDER + op_name + '_settings.json')\n",
    "    #vk_path = os.path.join(RUN_FOLDER + merge_id + '_test.vk')\n",
    "    vk_path = os.path.join(RUN_FOLDER + op_name + '_test.vk')\n",
    "\n",
    "    #print(proof_path)\n",
    "    #print(settings_path)\n",
    "    #print(vk_path)\n",
    "    assert os.path.isfile(proof_path)\n",
    "    assert os.path.isfile(settings_path)\n",
    "    assert os.path.isfile(vk_path)\n",
    "    res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path\n",
    "    )\n",
    "    assert res == True\n",
    "    print(op_name + \" verified\")\n",
    "    return res\n",
    "    \n",
    "async def verify_proofs(merge_id, mutate_id):\n",
    "    '''\n",
    "    proof_path = os.path.join(RUN_FOLDER + merge_id + '_test.pf')\n",
    "    settings_path = os.path.join(RUN_FOLDER + 'settings.json')\n",
    "    #vk_path = os.path.join(RUN_FOLDER + merge_id + '_test.vk')\n",
    "    vk_path = os.path.join(RUN_FOLDER + 'merge_test.vk')\n",
    "\n",
    "    #print(proof_path)\n",
    "    #print(settings_path)\n",
    "    #print(vk_path)\n",
    "    assert os.path.isfile(proof_path)\n",
    "    assert os.path.isfile(settings_path)\n",
    "    assert os.path.isfile(vk_path)\n",
    "    res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path\n",
    "    )\n",
    "    assert res == True\n",
    "    print(\"merge verified\")\n",
    "    '''\n",
    "    #res = await verify_proof('merge', merge_id)\n",
    "    #res = await verify_proof('mutate', mutate_id)\n",
    "    res = await asyncio.gather(verify_proof('merge', merge_id), verify_proof('mutate', mutate_id))\n",
    "    return res\n",
    "    '''\n",
    "    proof_path = os.path.join(RUN_FOLDER + mutate_id + '_test.pf')\n",
    "    settings_path = os.path.join(RUN_FOLDER + 'mutate_settings.json')\n",
    "    vk_path = os.path.join(RUN_FOLDER + 'mutate_test.vk')\n",
    "\n",
    "    #print(proof_path)\n",
    "    #print(settings_path)\n",
    "    #print(vk_path)\n",
    "    print(proof_path)\n",
    "    print(settings_path)\n",
    "    print(vk_path)\n",
    "    assert os.path.isfile(proof_path)\n",
    "    assert os.path.isfile(settings_path)\n",
    "    assert os.path.isfile(vk_path)\n",
    "    res = ezkl.verify(\n",
    "        proof_path,\n",
    "        settings_path,\n",
    "        vk_path\n",
    "    )\n",
    "    assert res == True\n",
    "    print(\"mutate verified\")\n",
    "    return res\n",
    "    '''\n",
    "    \n",
    "\n",
    "async def aggregate_merge_and_mutate(merge_id, mutate_id):\n",
    "    merge_proof_path = os.path.join(RUN_FOLDER + merge_id + '_test.pf')\n",
    "    mutate_proof_path = os.path.join(RUN_FOLDER + mutate_id + '_test.pf')\n",
    "    print('Aggregating ' + merge_proof_path + ' and ' + mutate_proof_path + ' ...')\n",
    "    num_logrows = 24\n",
    "    res = await ezkl.get_srs(settings_path=None, logrows=num_logrows, commitment=ezkl.PyCommitments.KZG)\n",
    "    res = ezkl.mock_aggregate([merge_proof_path, mutate_proof_path], num_logrows)\n",
    "    assert res == True\n",
    "\n",
    "    aggregate_proof_path = os.path.join('aggr.pf')\n",
    "    aggregate_vk_path = os.path.join('aggr.vk')\n",
    "    aggregate_pk_path = os.path.join('aggr.pk')\n",
    "    # Setup the vk and pk for aggregate\n",
    "    res = ezkl.setup_aggregate(\n",
    "        [merge_proof_path, mutate_proof_path],\n",
    "        aggregate_vk_path,\n",
    "        aggregate_pk_path,\n",
    "        num_logrows\n",
    "    )\n",
    "    aggr_proof = ezkl.aggregate(\n",
    "        [merge_proof_path, mutate_proof_path],\n",
    "        aggregate_proof_path,\n",
    "        aggregate_pk_path,\n",
    "        \"evm\",\n",
    "        num_logrows,\n",
    "        \"safe\"\n",
    "    )\n",
    "    \n",
    "    assert os.path.isfile(aggregate_proof_path)\n",
    "    \n",
    "    assert os.path.isfile(aggregate_vk_path)\n",
    "    assert os.path.isfile(aggregate_pk_path)\n",
    "    # Check if the proof is valid\n",
    "    res = ezkl.verify_aggr(\n",
    "        aggregate_proof_path,\n",
    "        aggregate_vk_path,\n",
    "        num_logrows,\n",
    "    )\n",
    "    assert res == True\n",
    "    print('verified aggregate')\n",
    "\n",
    "    return aggr_proof\n",
    "\n",
    "\n",
    "async def verify_all_proofs(merge_idx_and_p_inds):\n",
    "    merge_ids = []\n",
    "    mutate_ids = []\n",
    "    for iteration, merge_list in enumerate(merge_idx_and_p_inds):\n",
    "        for merge in merge_list:\n",
    "            merge_id = 'iter_' + str(iteration) + '_merge_idx_' + str(int(merge[0])) + '_p1_' + str(int(merge[1])) + '_p2_' + str(int(merge[2]))\n",
    "            merge_ids.append(merge_id)\n",
    "            mutate_id = 'iter_' + str(iteration) + '_merge_idx_' + str(int(merge[0])) + '_mutate'\n",
    "            mutate_ids.append(mutate_id)\n",
    "    await asyncio.gather(*(verify_proofs(merge_id, mutate_id) for (merge_id, mutate_id) in zip(merge_ids, mutate_ids)))\n",
    "\n",
    "\n",
    "async def verify_only_best_path_proofs(merge_idx_and_p_inds, best_ind):\n",
    "    # given the ending best performing model, get each proof in the tree of proofs that is necessary to prove the parent models\n",
    "    parents_to_verify = [tuple(merge_idx_and_p_inds[-1][best_ind].tolist())] # get the parent indices of the best model of in the last iteration\n",
    "    merge_ids = set()\n",
    "    mutate_ids = set()\n",
    "    all_ids = set()\n",
    "    for iteration in reversed(range(len(merge_idx_and_p_inds))):\n",
    "        # verify current parents\n",
    "        new_parents = []\n",
    "        for parents in parents_to_verify:\n",
    "            print(parents_to_verify)\n",
    "            merge_idx = parents[0]\n",
    "            print('Model ' + str(merge_idx) + ' from iteration ' + str(iteration) + ' has parents ' + str(int(parents[1])) + ' and ' + str(int(parents[2])) + ' from iteration ' + str(iteration-1))\n",
    "            merge_id = 'iter_' + str(int(iteration)) + '_merge_idx_' + str(int(merge_idx)) + '_p1_' + str(int(parents[1])) + '_p2_' + str(int(parents[2]))\n",
    "            grandparents_p1 = tuple(merge_idx_and_p_inds[iteration-1][parents[1]].tolist())\n",
    "            grandparents_p2 = tuple(merge_idx_and_p_inds[iteration-1][parents[2]].tolist())\n",
    "            new_parents.append(grandparents_p1)\n",
    "            new_parents.append(grandparents_p2)\n",
    "            \n",
    "            mutate_id = 'iter_' + str(iteration) + '_merge_idx_' + str(int(merge_idx)) + '_mutate'\n",
    "            merge_ids.add(merge_id)\n",
    "            mutate_ids.add(mutate_id)\n",
    "            all_ids.add((merge_id, mutate_id))\n",
    "            #print('The parents of ' + merge_id + ' are ' + 'iter_' + str(int(iteration-1)) + '_merge_idx_' + str(int(parents[0])) + '_p1_' + str(int(new_parents[0][1])) + '_p2_' + str(int(new_parents[0][2])) + ' and ' \\\n",
    "            #    'iter_' + str(int(iteration-1)) + '_merge_idx_' + str(int(parents[1])) + '_p1_' + str(int(new_parents[1][1])) + '_p2_' + str(int(new_parents[1][2])))\n",
    "        print('Iteration ' + str(iteration))\n",
    "        parents_to_verify = set(new_parents) # don't include the same parents twice\n",
    "        print(parents_to_verify)\n",
    "        print('number of parents to verify ' + str(len(parents_to_verify)))\n",
    "\n",
    "    #return await asyncio.gather(*(verify_proofs(merge_id) for merge_id in merge_ids))\n",
    "    #await asyncio.gather(*(aggregate_merge_and_mutate(merge_id, mutate_id) for (merge_id, mutate_id) in all_ids))\n",
    "    #await aggregate_merge_and_mutate(*(list(all_ids)[0]))\n",
    "    return await asyncio.gather(*(verify_proofs(merge_id, mutate_id) for (merge_id, mutate_id) in all_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 0, 2)]\n",
      "Model 3 from iteration 4 has parents 0 and 2 from iteration 3\n",
      "Iteration 4\n",
      "{(2, 0, 1), (0, 1, 1)}\n",
      "number of parents to verify 2\n",
      "{(2, 0, 1), (0, 1, 1)}\n",
      "Model 2 from iteration 3 has parents 0 and 1 from iteration 2\n",
      "{(2, 0, 1), (0, 1, 1)}\n",
      "Model 0 from iteration 3 has parents 1 and 1 from iteration 2\n",
      "Iteration 3\n",
      "{(1, 2, 1), (0, 3, 0)}\n",
      "number of parents to verify 2\n",
      "{(1, 2, 1), (0, 3, 0)}\n",
      "Model 1 from iteration 2 has parents 2 and 1 from iteration 1\n",
      "{(1, 2, 1), (0, 3, 0)}\n",
      "Model 0 from iteration 2 has parents 3 and 0 from iteration 1\n",
      "Iteration 2\n",
      "{(0, 2, 0), (3, 1, 1), (1, 1, 1), (2, 2, 2)}\n",
      "number of parents to verify 4\n",
      "{(0, 2, 0), (3, 1, 1), (1, 1, 1), (2, 2, 2)}\n",
      "Model 0 from iteration 1 has parents 2 and 0 from iteration 0\n",
      "{(0, 2, 0), (3, 1, 1), (1, 1, 1), (2, 2, 2)}\n",
      "Model 3 from iteration 1 has parents 1 and 1 from iteration 0\n",
      "{(0, 2, 0), (3, 1, 1), (1, 1, 1), (2, 2, 2)}\n",
      "Model 1 from iteration 1 has parents 1 and 1 from iteration 0\n",
      "{(0, 2, 0), (3, 1, 1), (1, 1, 1), (2, 2, 2)}\n",
      "Model 2 from iteration 1 has parents 2 and 2 from iteration 0\n",
      "Iteration 1\n",
      "{(1, 1, 0), (0, 1, 1), (2, 0, 0)}\n",
      "number of parents to verify 3\n",
      "{(1, 1, 0), (0, 1, 1), (2, 0, 0)}\n",
      "Model 1 from iteration 0 has parents 1 and 0 from iteration -1\n",
      "{(1, 1, 0), (0, 1, 1), (2, 0, 0)}\n",
      "Model 0 from iteration 0 has parents 1 and 1 from iteration -1\n",
      "{(1, 1, 0), (0, 1, 1), (2, 0, 0)}\n",
      "Model 2 from iteration 0 has parents 0 and 0 from iteration -1\n",
      "Iteration 0\n",
      "{(1, 3, 2), (0, 2, 3)}\n",
      "number of parents to verify 2\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "Proof verification duration (best path):13.49128246307373\n"
     ]
    }
   ],
   "source": [
    "verify_start = time.time()\n",
    "best_ind = top_inds[0]\n",
    "await verify_only_best_path_proofs(merge_idx_and_p_inds, best_ind)\n",
    "verify_end = time.time()\n",
    "\n",
    "verify_duration = verify_end - verify_start\n",
    "print('Proof verification duration (best path):' + str(verify_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "merge verified\n",
      "mutate verified\n",
      "Proof verification duration (all):56.248370885849\n"
     ]
    }
   ],
   "source": [
    "verify_start = time.time()\n",
    "await verify_all_proofs(merge_idx_and_p_inds)\n",
    "#best_ind = top_inds[0]\n",
    "#await verify_only_best_path_proofs(merge_idx_and_p_inds, best_ind)\n",
    "verify_end = time.time()\n",
    "\n",
    "verify_duration = verify_end - verify_start\n",
    "print('Proof verification duration (all):' + str(verify_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 8 columns for non-linearity table.\n",
      "Using 8 columns for non-linearity table.\n",
      "Using 8 columns for non-linearity table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64])\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 8 columns for non-linearity table.\n",
      "Using 8 columns for non-linearity table.\n",
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 11, param_scale: 11, scale_input_multiplier: 1) ------------->\n",
      "\n",
      "+----------------+----------------+----------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error     | median_error   | max_error      | min_error      | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+----------------+----------------+----------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| -0.00016275048 | -0.00016275048 | -0.00016275048 | -0.00016275048 | 0.00016275048  | 0.00016275048    | 0.00016275048 | 0.00016275048 | 0.000000026487719  | -0.00048825145     | 0.00048825145          |\n",
      "+----------------+----------------+----------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nmodel_path = os.path.join(RUN_FOLDER + \\'eval.onnx\\')\\ncompiled_model_path = os.path.join(RUN_FOLDER + \\'eval_network.compiled\\')\\npk_path = os.path.join(RUN_FOLDER + \\'test.pk\\')\\nvk_path = os.path.join(RUN_FOLDER + \\'test.vk\\')\\nsettings_path = os.path.join(RUN_FOLDER + \\'settings.json\\')                                            \\n                                                                                                               \\nwitness_path = os.path.join(RUN_FOLDER + \\'witness.json\\')                                              \\n                                                                                                               \\ndata_path = os.path.join(RUN_FOLDER + \\'test_input.json\\')    \\neval_mod = torch.jit.script(eval_mod)\\n\\ntorch.onnx.export(\\n    eval_mod,                       # the model/module to be exported\\n    (images, labels),                 # example inputs\\n    model_path,                # the file name to save the ONNX model\\n    export_params=True,          # store the trained parameter weights inside the model file\\n    opset_version=11,            # the ONNX version to export the model to\\n    do_constant_folding=True,    # whether to execute constant folding for optimization\\n    input_names=[\\'images\\', \\'labels\\'],  # input names\\n    output_names=[\\'acc\\']        # output name\\n)\\n\\npy_run_args = ezkl.PyRunArgs()\\npy_run_args.input_visibility = \"public\"\\npy_run_args.output_visibility = \"public\"\\npy_run_args.param_visibility = \"fixed\"\\nres = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\\ncal_path = os.path.join(RUN_FOLDER + \"calibration.json\")\\n# data = dict(input_data = [torch.rand(*images.shape).detach().numpy().reshape(-1).tolist(),\\n#                          torch.rand(*labels.shape).detach().numpy().reshape(-1).tolist()])\\ndata = dict(input_data = [images.detach().numpy().reshape(-1).tolist(),\\n                       labels.detach().numpy().reshape(-1).tolist()])\\n\\n\\njson.dump(data, open(cal_path, \\'w\\'))\\n# calibrate\\nstart_cal = time.time()\\nawait ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\\nend_cal = time.time()\\ncal_dur = end_cal - start_cal\\nprint(\\'Calibration duration: \\' + str(cal_dur))\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## EVALUATION\n",
    "batch_size = 3\n",
    "\n",
    "class EvaluateModel(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        # self.X = X\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, X, y):\n",
    "        logits = self.model(X)\n",
    "        return get_acc(logits, y)\n",
    "\n",
    "def get_acc(logits, labels):\n",
    "    predicted_labels = logits.argmax(dim=-1)\n",
    "    return (predicted_labels == labels).float().mean()\n",
    "\n",
    "best_model = reroll_params(elites[0])\n",
    "eval_mod = EvaluateModel(best_model)\n",
    "RUN_FOLDER = \"./test_eval_dir/\"\n",
    "\n",
    "from pathlib import Path\n",
    "Path(RUN_FOLDER).mkdir(parents=True, exist_ok=True) # create directory and any intermediate directories\n",
    "\n",
    "\n",
    "images = images[:batch_size, :]\n",
    "labels = labels[:batch_size]\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "op_name = 'eval'\n",
    "example_inputs = (images, labels)\n",
    "calibration_inputs = [images.detach().numpy().reshape(-1).tolist(),\n",
    "                       labels.detach().numpy().reshape(-1).tolist()]\n",
    "input_names = ['images', 'labels']\n",
    "output_names = ['acc']\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(calibrate_operation(op_name, example_inputs, calibration_inputs, input_names, eval_mod, output_names))\n",
    "\n",
    "'''\n",
    "model_path = os.path.join(RUN_FOLDER + 'eval.onnx')\n",
    "compiled_model_path = os.path.join(RUN_FOLDER + 'eval_network.compiled')\n",
    "pk_path = os.path.join(RUN_FOLDER + 'test.pk')\n",
    "vk_path = os.path.join(RUN_FOLDER + 'test.vk')\n",
    "settings_path = os.path.join(RUN_FOLDER + 'settings.json')                                            \n",
    "                                                                                                               \n",
    "witness_path = os.path.join(RUN_FOLDER + 'witness.json')                                              \n",
    "                                                                                                               \n",
    "data_path = os.path.join(RUN_FOLDER + 'test_input.json')    \n",
    "eval_mod = torch.jit.script(eval_mod)\n",
    "\n",
    "torch.onnx.export(\n",
    "    eval_mod,                       # the model/module to be exported\n",
    "    (images, labels),                 # example inputs\n",
    "    model_path,                # the file name to save the ONNX model\n",
    "    export_params=True,          # store the trained parameter weights inside the model file\n",
    "    opset_version=11,            # the ONNX version to export the model to\n",
    "    do_constant_folding=True,    # whether to execute constant folding for optimization\n",
    "    input_names=['images', 'labels'],  # input names\n",
    "    output_names=['acc']        # output name\n",
    ")\n",
    "\n",
    "py_run_args = ezkl.PyRunArgs()\n",
    "py_run_args.input_visibility = \"public\"\n",
    "py_run_args.output_visibility = \"public\"\n",
    "py_run_args.param_visibility = \"fixed\"\n",
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "cal_path = os.path.join(RUN_FOLDER + \"calibration.json\")\n",
    "# data = dict(input_data = [torch.rand(*images.shape).detach().numpy().reshape(-1).tolist(),\n",
    "#                          torch.rand(*labels.shape).detach().numpy().reshape(-1).tolist()])\n",
    "data = dict(input_data = [images.detach().numpy().reshape(-1).tolist(),\n",
    "                       labels.detach().numpy().reshape(-1).tolist()])\n",
    "\n",
    "\n",
    "json.dump(data, open(cal_path, 'w'))\n",
    "# calibrate\n",
    "start_cal = time.time()\n",
    "await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
    "end_cal = time.time()\n",
    "cal_dur = end_cal - start_cal\n",
    "print('Calibration duration: ' + str(cal_dur))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nstart_comp = time.time()\\nres = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\\nend_comp = time.time()\\ncomp_dur = end_comp - start_comp\\nprint('Circuit compilation duration: ' + str(comp_dur))\\n\\nassert res == True\\n\\nsrs_start = time.time()\\nres = await ezkl.get_srs( settings_path)\\nassert res == True\\nsrs_end = time.time()\\nsrs_dur = srs_end - srs_start\\nprint('SRS duration: ' + str(srs_dur))\\n\""
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "start_comp = time.time()\n",
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "end_comp = time.time()\n",
    "comp_dur = end_comp - start_comp\n",
    "print('Circuit compilation duration: ' + str(comp_dur))\n",
    "\n",
    "assert res == True\n",
    "\n",
    "srs_start = time.time()\n",
    "res = await ezkl.get_srs( settings_path)\n",
    "assert res == True\n",
    "srs_end = time.time()\n",
    "srs_dur = srs_end - srs_start\n",
    "print('SRS duration: ' + str(srs_dur))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel_path = os.path.join(RUN_FOLDER + 'eval.onnx')\\ncompiled_model_path = os.path.join(RUN_FOLDER + 'eval_network.compiled')\\npk_path = os.path.join(RUN_FOLDER + 'test.pk')\\nvk_path = os.path.join(RUN_FOLDER + 'test.vk')\\nsettings_path = os.path.join(RUN_FOLDER + 'settings.json')                                            \\n\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''\n",
    "model_path = os.path.join(RUN_FOLDER + 'eval.onnx')\n",
    "compiled_model_path = os.path.join(RUN_FOLDER + 'eval_network.compiled')\n",
    "pk_path = os.path.join(RUN_FOLDER + 'test.pk')\n",
    "vk_path = os.path.join(RUN_FOLDER + 'test.vk')\n",
    "settings_path = os.path.join(RUN_FOLDER + 'settings.json')                                            \n",
    "'''\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 64])\n",
      "torch.Size([1797])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                               | 0/4 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "images, labels = datasets.load_digits(return_X_y=True)\n",
    "images = torch.tensor(images, dtype=torch.float32)\n",
    "labels = torch.tensor(labels, dtype=torch.int64)\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "total_chunks = images.shape[0] // batch_size # assumes divisible\n",
    "'''\n",
    "proof_setup_start = time.time()\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)\n",
    "\n",
    "proof_setup_end = time.time()\n",
    "proof_setup_dur = proof_setup_end - proof_setup_start\n",
    "print('Proof setup duration: ' + str(proof_setup_dur))\n",
    "'''\n",
    "\n",
    "import tqdm\n",
    "total_chunks = 4 # for testing\n",
    "op_name = 'eval'\n",
    "for i in tqdm.tqdm(range(total_chunks)):\n",
    "    operation_save_name = f'eval_batch_{i}'\n",
    "    inputs = [images[i * batch_size: (i + 1) * batch_size, :].detach().numpy().reshape(-1).tolist(),\n",
    "                        labels[i * batch_size: (i + 1) * batch_size].detach().numpy().reshape(-1).tolist()]\n",
    "    res = await prove_operation(op_name, operation_save_name, inputs)\n",
    "    \n",
    "    '''\n",
    "    witness_path = os.path.join(RUN_FOLDER + f'witness_{i}.json')                                              \n",
    "    data_path = os.path.join(RUN_FOLDER + f'actual_test_input_{i}.json')\n",
    "    with open(data_path, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "    witness_start = time.time()\n",
    "    res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "    assert os.path.isfile(witness_path)\n",
    "    witness_end = time.time()\n",
    "    witness_dur = witness_end - witness_start\n",
    "    #print('Witness duration: ' + str(witness_dur))\n",
    "\n",
    "\n",
    "    proof_path = os.path.join(RUN_FOLDER + f\"test_proof_{i}.pf\")\n",
    "    proof_start = time.time()\n",
    "    # prove\n",
    "    res = ezkl.prove(\n",
    "            witness_path,\n",
    "            compiled_model_path,\n",
    "            pk_path,\n",
    "            proof_path,\n",
    "\n",
    "            \"single\",\n",
    "        )\n",
    "\n",
    "    #print(res)\n",
    "    proof_end = time.time()\n",
    "    proof_duration = proof_end - proof_start\n",
    "    #print('Proof duration: ' + str(proof_duration))\n",
    "    '''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "Total verify duration: 10.618655443191528\n"
     ]
    }
   ],
   "source": [
    "start_verify = time.time()\n",
    "for i in range(total_chunks):\n",
    "    witness_path = os.path.join(RUN_FOLDER + f'witness_{i}.json')\n",
    "    proof_path = os.path.join(RUN_FOLDER + f\"test_proof_{i}.pf\")\n",
    "    res = ezkl.verify(\n",
    "            proof_path,\n",
    "            settings_path,\n",
    "            vk_path\n",
    "        )\n",
    "    assert res == True\n",
    "    print(\"verified\")\n",
    "    \n",
    "end_verify = time.time()\n",
    "verify_dur = end_verify - start_verify\n",
    "print('Total verify duration: ' + str(verify_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
