{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwPU6S1ZdUN8",
        "outputId": "fb430210-3e7d-42eb-ab26-0db9538130a4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data information\n",
            "====================\n",
            "#samples=1797, image_size=torch.Size([64])\n",
            "#odd_num_images=906\n",
            "#even_num_images=891\n",
            "num_params=19210\n"
          ]
        }
      ],
      "source": [
        "# Import libraries\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import json\n",
        "import asyncio\n",
        "from sklearn import datasets\n",
        "from tqdm import tqdm\n",
        "\n",
        "# check if notebook is in colab\n",
        "try:\n",
        "    # install ezkl\n",
        "    import google.colab\n",
        "    import subprocess\n",
        "    import sys\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
        "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
        "\n",
        "# rely on local installation of ezkl if the notebook is not in colab\n",
        "except:\n",
        "    pass\n",
        "\n",
        "import ezkl\n",
        "import os\n",
        "import nest_asyncio\n",
        "\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# Task definition\n",
        "\n",
        "print('Data information')\n",
        "print('=' * 20)\n",
        "\n",
        "images, labels = datasets.load_digits(return_X_y=True)\n",
        "images = torch.tensor(images, dtype=torch.float32)\n",
        "labels = torch.tensor(labels, dtype=torch.int64)\n",
        "print(f'#samples={len(images)}, image_size={images[0].shape}')\n",
        "\n",
        "mask = labels % 2 == 1\n",
        "odd_num_images, odd_num_labels = images[mask], labels[mask]\n",
        "print(f'#odd_num_images={len(odd_num_images)}')\n",
        "\n",
        "mask = labels % 2 == 0\n",
        "even_num_images, even_num_labels = images[mask], labels[mask]\n",
        "print(f'#even_num_images={len(even_num_images)}')\n",
        "\n",
        "# Neural network definition\n",
        "hidden_dim = 256\n",
        "input_dim = 64\n",
        "output_dim = 10\n",
        "num_params = (1 + input_dim) * hidden_dim + (1 + hidden_dim) * output_dim\n",
        "print(f'num_params={num_params}')\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MLP, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "def get_loss(model, data, labels):\n",
        "    logits = model(data)\n",
        "    log_probs = F.log_softmax(logits, dim=1)\n",
        "    true_log_probs = log_probs.gather(1, labels.view(-1, 1))\n",
        "    return -true_log_probs.mean()\n",
        "\n",
        "\n",
        "def get_grad(model, data, labels):\n",
        "    model.zero_grad()\n",
        "    loss = get_loss(model, data, labels)\n",
        "    loss.backward()\n",
        "    return model.parameters()\n",
        "\n",
        "\n",
        "def get_acc(logits, labels):\n",
        "    predicted_labels = logits.argmax(dim=1)\n",
        "    return (predicted_labels == labels).float().mean().item()\n",
        "\n",
        "\n",
        "def train(model, x, y, lr=0.003, num_epochs=10):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    for _ in range(num_epochs):\n",
        "        optimizer.zero_grad()\n",
        "        loss = get_loss(model, x, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    return model\n",
        "\n",
        "\n",
        "# Test\n",
        "mlp = MLP()\n",
        "rand_params = torch.randn(num_params) * 0.01\n",
        "mlp.fc1.weight.data = rand_params[:hidden_dim * input_dim].view(hidden_dim, input_dim)\n",
        "mlp.fc1.bias.data = rand_params[hidden_dim * input_dim:hidden_dim * input_dim + hidden_dim]\n",
        "mlp.fc2.weight.data = rand_params[-(output_dim * hidden_dim + output_dim):-output_dim].view(output_dim, hidden_dim)\n",
        "mlp.fc2.bias.data = rand_params[-output_dim:]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(images.shape)\n",
        "logits = mlp(images)\n",
        "loss = get_loss(mlp, images, labels)\n",
        "acc = get_acc(logits, labels)\n",
        "print(f'Random MLP: loss={loss.item():.4f}, acc={acc:.2f}')\n",
        "\n",
        "# Train 2 seed MLPs\n",
        "mlp1 = MLP()\n",
        "mlp2 = MLP()\n",
        "\n",
        "mlp1 = train(mlp1, odd_num_images, odd_num_labels)\n",
        "mlp2 = train(mlp2, even_num_images, even_num_labels)\n",
        "\n",
        "models = [mlp1, mlp2]\n",
        "model_names = ['mlp1', 'mlp2']\n",
        "for model, model_name in zip(models, model_names):\n",
        "    for x, y, name in zip([odd_num_images, even_num_images, images], [odd_num_labels, even_num_labels, labels], ['d_odd', 'd_even', 'd0-9']):\n",
        "        logits = model(x)\n",
        "        acc = get_acc(logits, y)\n",
        "        print(f'{model_name} acc@{name}={acc:.2f}')\n",
        "    print('-' * 10)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmazpzbAe5rr",
        "outputId": "e37ca022-ef6e-4c0a-b166-f78b9e2cca15"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1797, 64])\n",
            "Random MLP: loss=2.3040, acc=0.04\n",
            "mlp1 acc@d_odd=0.95\n",
            "mlp1 acc@d_even=0.00\n",
            "mlp1 acc@d0-9=0.48\n",
            "----------\n",
            "mlp2 acc@d_odd=0.00\n",
            "mlp2 acc@d_even=0.98\n",
            "mlp2 acc@d0-9=0.49\n",
            "----------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evolutionary algorithm merging\n",
        "#n_iter = 1000\n",
        "n_iter = 25\n",
        "mutation_std = 0.01\n",
        "pop_size = 512\n",
        "num_elite = 8\n",
        "seed = 42\n",
        "\n",
        "class Slerp(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Slerp, self).__init__()\n",
        "\n",
        "    def forward(self, val, x, y):\n",
        "      norm_x = F.normalize(x, dim=-1)\n",
        "      norm_y = F.normalize(y, dim=-1)\n",
        "      dot = torch.sum(norm_x * norm_y, dim=-1, keepdim=True)\n",
        "      omega = torch.acos(torch.clamp(dot, -1.0, 1.0))\n",
        "      sin_omega = torch.sin(omega)\n",
        "      scale_x = torch.sin((1.0 - val) * omega) / sin_omega\n",
        "      scale_y = torch.sin(val * omega) / sin_omega\n",
        "      lin_scale_x = 1.0 - val\n",
        "      lin_scale_y = val\n",
        "      return torch.where(sin_omega > 1e-6, scale_x * x + scale_y * y, lin_scale_x * x + lin_scale_y * y)\n",
        "\n",
        "'''\n",
        "def slerp(val, x, y):\n",
        "    norm_x = F.normalize(x, dim=-1)\n",
        "    norm_y = F.normalize(y, dim=-1)\n",
        "    dot = torch.sum(norm_x * norm_y, dim=-1, keepdim=True)\n",
        "    omega = torch.acos(torch.clamp(dot, -1.0, 1.0))\n",
        "    sin_omega = torch.sin(omega)\n",
        "    scale_x = torch.sin((1.0 - val) * omega) / sin_omega\n",
        "    scale_y = torch.sin(val * omega) / sin_omega\n",
        "    lin_scale_x = 1.0 - val\n",
        "    lin_scale_y = val\n",
        "    return torch.where(sin_omega > 1e-6, scale_x * x + scale_y * y, lin_scale_x * x + lin_scale_y * y)\n",
        "'''\n",
        "slerp = Slerp()\n",
        "\n",
        "'''\n",
        "def crossover(parents):\n",
        "    w = torch.rand(1)\n",
        "    return slerp(w, parents[0], parents[1])\n",
        "'''\n",
        "async def zk_verify_merge(val, parent_1, parent_2):\n",
        "    model_path = os.path.join('slerp.onnx')\n",
        "    compiled_model_path = os.path.join('network.compiled')\n",
        "    pk_path = os.path.join('test.pk')\n",
        "    vk_path = os.path.join('test.vk')\n",
        "    settings_path = os.path.join('settings.json')\n",
        "\n",
        "    witness_path = os.path.join('witness.json')\n",
        "    data_path = os.path.join('slerp_input.json')\n",
        "\n",
        "    torch.onnx.export(\n",
        "        slerp,                       # the model/module to be exported\n",
        "        (val, parent_1, parent_2),                 # example inputs\n",
        "        \"slerp.onnx\",                # the file name to save the ONNX model\n",
        "        export_params=True,          # store the trained parameter weights inside the model file\n",
        "        opset_version=11,            # the ONNX version to export the model to\n",
        "        do_constant_folding=True,    # whether to execute constant folding for optimization\n",
        "        input_names=['val', 'x', 'y'],  # input names\n",
        "        output_names=['result'],        # output name\n",
        "        dynamic_axes={'x': {0: 'batch_size'}, 'y': {0: 'batch_size'}, 'result': {0: 'batch_size'}}  # dynamic axis\n",
        "    )\n",
        "    input_data = {\n",
        "        'val': val.item(),        # scalar value\n",
        "        'parent_1': parent_1.tolist(),          # tensor to list\n",
        "        'parent_2': parent_2.tolist()           # tensor to list\n",
        "    }\n",
        "    with open(\"slerp_input.json\", \"w\") as f:\n",
        "        json.dump(input_data, f)\n",
        "\n",
        "    py_run_args = ezkl.PyRunArgs()\n",
        "    py_run_args.input_visibility = \"public\"\n",
        "    py_run_args.output_visibility = \"public\"\n",
        "    py_run_args.param_visibility = \"fixed\" # \"fixed\" for params means that the committed to params are used for all proofs\n",
        "\n",
        "    res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
        "    assert res == True\n",
        "\n",
        "    #cal_path = os.path.join(\"calibration.json\")\n",
        "\n",
        "    #data_array = (torch.rand(20, *parent_1.shape, requires_grad=True).detach().numpy()).reshape([-1]).tolist()\n",
        "\n",
        "    #data = dict(input_data = [data_array])\n",
        "\n",
        "    # Serialize data into file:\n",
        "    data = {\n",
        "        'val': val.item(),        # scalar value\n",
        "        'parent_1': torch.rand(20, *parent_1.shape).tolist(),          # tensor to list\n",
        "        'parent_2': torch.rand(20, *parent_2.shape).tolist()           # tensor to list\n",
        "    }\n",
        "    cal_path = os.path.join(\"calibration.json\")\n",
        "\n",
        "    json.dump(data, open(cal_path, 'w'))\n",
        "\n",
        "    await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
        "\n",
        "    res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
        "    assert res == True\n",
        "\n",
        "    # srs path\n",
        "    res = ezkl.get_srs( settings_path)\n",
        "\n",
        "    # now generate the witness file\n",
        "\n",
        "    res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
        "    assert os.path.isfile(witness_path)\n",
        "\n",
        "\n",
        "    # HERE WE SETUP THE CIRCUIT PARAMS\n",
        "    # WE GOT KEYS\n",
        "    # WE GOT CIRCUIT PARAMETERS\n",
        "    # EVERYTHING ANYONE HAS EVER NEEDED FOR ZK\n",
        "\n",
        "\n",
        "\n",
        "    res = ezkl.setup(\n",
        "            compiled_model_path,\n",
        "            vk_path,\n",
        "            pk_path,\n",
        "\n",
        "        )\n",
        "\n",
        "    assert res == True\n",
        "    assert os.path.isfile(vk_path)\n",
        "    assert os.path.isfile(pk_path)\n",
        "    assert os.path.isfile(settings_path)\n",
        "\n",
        "    # GENERATE A PROOF\n",
        "\n",
        "\n",
        "    proof_path = os.path.join('test.pf')\n",
        "\n",
        "    res = ezkl.prove(\n",
        "            witness_path,\n",
        "            compiled_model_path,\n",
        "            pk_path,\n",
        "            proof_path,\n",
        "\n",
        "            \"single\",\n",
        "        )\n",
        "\n",
        "    print(res)\n",
        "    assert os.path.isfile(proof_path)\n",
        "\n",
        "    # VERIFY IT\n",
        "\n",
        "    res = ezkl.verify(\n",
        "            proof_path,\n",
        "            settings_path,\n",
        "            vk_path,\n",
        "\n",
        "        )\n",
        "\n",
        "    assert res == True\n",
        "    print(\"verified\")\n",
        "    return res\n",
        "\n",
        "def crossover(parents):\n",
        "    val = torch.rand(1)\n",
        "    #asyncio.run(zk_verify_merge(val, parents[0], parents[1]))\n",
        "    loop = asyncio.get_event_loop()\n",
        "    verified = loop.run_until_complete(zk_verify_merge(val, parents[0], parents[1]))\n",
        "    #verified = loop.create_task(zk_verify_merge(val, parents[0], parents[1]))\n",
        "    print(verified)\n",
        "    result = slerp(val, parents[0], parents[1])\n",
        "    return result\n",
        "\n",
        "\n",
        "def mutate(gene):\n",
        "    noise = torch.randn(gene.shape) * mutation_std\n",
        "    return gene + noise\n",
        "\n",
        "def ask(elite_solutions):\n",
        "    parents_indices = torch.randint(0, num_elite, (pop_size * 2,))\n",
        "    parents = elite_solutions[parents_indices].view(pop_size, 2, -1)\n",
        "    population = torch.stack([crossover(p) for p in parents])\n",
        "    population = torch.stack([mutate(g) for g in population])\n",
        "    return population\n",
        "\n",
        "def get_flat_params(model):\n",
        "    return torch.concatenate([p.view(-1) for p in model.parameters()])\n",
        "\n",
        "def tell(population, scores):\n",
        "    top_scores, top_indices = scores.topk(num_elite)\n",
        "    #print('scores')\n",
        "    #print(scores.shape)\n",
        "    #print('elite solns')\n",
        "    #print(elite_solutions.shape)\n",
        "    #print('top inds')\n",
        "    #print(top_indices)\n",
        "    new_elites = population[top_indices]\n",
        "    new_elites[-1] = get_flat_params(mlp1)\n",
        "    new_elites[-2] = get_flat_params(mlp2)\n",
        "    return new_elites\n",
        "\n",
        "'''\n",
        "def eval_params(params, x, y):\n",
        "    model = MLP()\n",
        "    # Load the model's parameters from the flattened params vector\n",
        "    model.fc1.weight.data = params[:hidden_dim * input_dim].view(hidden_dim, input_dim)\n",
        "    model.fc1.bias.data = params[hidden_dim * input_dim:hidden_dim * input_dim + hidden_dim]\n",
        "    model.fc2.weight.data = params[-(output_dim * hidden_dim + output_dim):-output_dim].view(output_dim, hidden_dim)\n",
        "    model.fc2.bias.data = params[-output_dim:]\n",
        "    logits = model(x)\n",
        "    return get_acc(logits, y)\n",
        "'''\n",
        "\n",
        "'''\n",
        "def eval_params(params, x, y):\n",
        "    model = MLP()\n",
        "    # Load the model's parameters from the flattened params vector, reshaping the weights\n",
        "    model.fc1.weight.data = params[:hidden_dim * input_dim].view(hidden_dim, input_dim)\n",
        "    model.fc1.bias.data = params[hidden_dim * input_dim:hidden_dim * input_dim + hidden_dim]\n",
        "    model.fc2.weight.data = params[-(output_dim * hidden_dim + output_dim):-output_dim].view(output_dim, hidden_dim)\n",
        "    model.fc2.bias.data = params[-output_dim:]\n",
        "    logits = model(x)\n",
        "    return get_acc(logits, y)\n",
        "'''\n",
        "def eval_params(params, x, y):\n",
        "    model = MLP()\n",
        "    # Load the model's parameters from the flattened params vector, reshaping the weights\n",
        "    model.fc1.weight.data = params[:hidden_dim * input_dim].view(hidden_dim, input_dim)\n",
        "\n",
        "    model.fc1.bias.data = params[(hidden_dim * input_dim):(hidden_dim * input_dim + hidden_dim)]\n",
        "\n",
        "    model.fc2.weight.data = params[-(output_dim * hidden_dim + output_dim):-output_dim].view(output_dim, hidden_dim)\n",
        "\n",
        "    model.fc2.bias.data = params[-output_dim:]\n",
        "\n",
        "    # Reshape the input data to match the expected input size of the model\n",
        "    x_reshaped = x.view(-1, input_dim)  # Reshape to [batch_size, input_dim]\n",
        "\n",
        "    logits = model(x_reshaped)  # Pass the reshaped input to the model\n",
        "    return get_acc(logits, y)\n",
        "\n",
        "# Initialize the elites with seed models\n",
        "mlp1_param = torch.concatenate([mlp1.state_dict()['fc1.weight'].view(-1), mlp1.state_dict()['fc1.bias'].view(-1), mlp1.state_dict()['fc2.weight'].view(-1), mlp1.state_dict()['fc2.bias'].view(-1)])\n",
        "mlp2_param = torch.concatenate([mlp2.state_dict()['fc1.weight'].view(-1), mlp2.state_dict()['fc1.bias'].view(-1), mlp2.state_dict()['fc2.weight'].view(-1), mlp2.state_dict()['fc2.bias'].view(-1)])\n",
        "elites = torch.stack([mlp1_param, mlp2_param])\n",
        "elites = elites[torch.randint(0, 2, (num_elite,))]\n",
        "\n",
        "# Optimization loop\n",
        "acc_max = []\n",
        "for i in tqdm(range(n_iter)):\n",
        "    population = ask(elites)\n",
        "    '''\n",
        "    print('Population:')\n",
        "    print(population.shape)\n",
        "    print('Images')\n",
        "    print(images.shape)\n",
        "    print(\"labels\")\n",
        "    print(labels.shape)\n",
        "    '''\n",
        "    #print(population.shape)\n",
        "    scores = torch.tensor([eval_params(p, images, labels) for p in population])\n",
        "    #print('score values')\n",
        "    #print(scores)\n",
        "    #elites = tell(elites, scores)\n",
        "    elites = tell(population, scores)\n",
        "    acc_max.append(scores.max().item())\n",
        "\n",
        "# Plot the results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(8, 3))\n",
        "\n",
        "ax = axes[0]\n",
        "ax.plot(np.maximum.accumulate(acc_max))\n",
        "ax.set_title('Best model performance')\n",
        "ax = axes[1]\n",
        "ax.plot(acc_max)\n",
        "ax.set_title('Max accuracy per generation')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "6EVdBmBnfA2m",
        "outputId": "641b1c70-6d5e-418c-d1b0-0f9ac7a26e48"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/25 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "Failed to calibrate settings: [graph] [json] missing field `input_data` at line 1 column 15574755",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-6424e7e35ad7>\u001b[0m in \u001b[0;36m<cell line: 247>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0macc_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m     '''\n\u001b[1;32m    250\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Population:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-6424e7e35ad7>\u001b[0m in \u001b[0;36mask\u001b[0;34m(elite_solutions)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mparents_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_elite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpop_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melite_solutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparents_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrossover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-6424e7e35ad7>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0mparents_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_elite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpop_size\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0mparents\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melite_solutions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mparents_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpop_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m     \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcrossover\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m     \u001b[0mpopulation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmutate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpopulation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-6424e7e35ad7>\u001b[0m in \u001b[0;36mcrossover\u001b[0;34m(parents)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;31m#asyncio.run(zk_verify_merge(val, parents[0], parents[1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0mloop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_event_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0mverified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzk_verify_merge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0;31m#verified = loop.create_task(zk_verify_merge(val, parents[0], parents[1]))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mverified\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     96\u001b[0m                 raise RuntimeError(\n\u001b[1;32m     97\u001b[0m                     'Event loop stopped before Future completed.')\n\u001b[0;32m---> 98\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_must_cancel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-52-6424e7e35ad7>\u001b[0m in \u001b[0;36mzk_verify_merge\u001b[0;34m(val, parent_1, parent_2)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0;32mawait\u001b[0m \u001b[0mezkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalibrate_settings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"resources\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mezkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/futures.py\u001b[0m in \u001b[0;36m__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_asyncio_future_blocking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mself\u001b[0m  \u001b[0;31m# This tells Task to wait for completion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"await wasn't used with future\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/tasks.py\u001b[0m in \u001b[0;36m__wakeup\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    302\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__wakeup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 304\u001b[0;31m             \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    305\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m             \u001b[0;31m# This may also be a cancellation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/asyncio/futures.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__log_traceback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exception_tb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Failed to calibrate settings: [graph] [json] missing field `input_data` at line 1 column 15574755"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rOor--I0gW1o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}