{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WwPU6S1ZdUN8",
    "outputId": "fb430210-3e7d-42eb-ab26-0db9538130a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data information\n",
      "====================\n",
      "#samples=1797, image_size=torch.Size([64])\n",
      "#odd_num_images=906\n",
      "#even_num_images=891\n",
      "num_params=19210\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import asyncio\n",
    "from sklearn import datasets\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "os.environ['ENABLE_ICICLE_GPU'] = 'true'\n",
    "os.environ['RUST_BACKTRACE']='full'\n",
    "\n",
    "# check if notebook is in colab\n",
    "try:\n",
    "    # install ezkl\n",
    "    import google.colab\n",
    "    import subprocess\n",
    "    import sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"ezkl\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"onnx\"])\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"nest_asyncio\"])\n",
    "\n",
    "# rely on local installation of ezkl if the notebook is not in colab\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import ezkl\n",
    "import os\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Task definition\n",
    "\n",
    "print('Data information')\n",
    "print('=' * 20)\n",
    "\n",
    "images, labels = datasets.load_digits(return_X_y=True)\n",
    "images = torch.tensor(images, dtype=torch.float32)\n",
    "labels = torch.tensor(labels, dtype=torch.int64)\n",
    "print(f'#samples={len(images)}, image_size={images[0].shape}')\n",
    "\n",
    "mask = labels % 2 == 1\n",
    "odd_num_images, odd_num_labels = images[mask], labels[mask]\n",
    "print(f'#odd_num_images={len(odd_num_images)}')\n",
    "\n",
    "mask = labels % 2 == 0\n",
    "even_num_images, even_num_labels = images[mask], labels[mask]\n",
    "print(f'#even_num_images={len(even_num_images)}')\n",
    "\n",
    "# Neural network definition\n",
    "hidden_dim = 256\n",
    "input_dim = 64\n",
    "output_dim = 10\n",
    "num_params = (1 + input_dim) * hidden_dim + (1 + hidden_dim) * output_dim\n",
    "print(f'num_params={num_params}')\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def get_loss(model, data, labels):\n",
    "    logits = model(data)\n",
    "    log_probs = F.log_softmax(logits, dim=1)\n",
    "    true_log_probs = log_probs.gather(1, labels.view(-1, 1))\n",
    "    return -true_log_probs.mean()\n",
    "\n",
    "\n",
    "def get_grad(model, data, labels):\n",
    "    model.zero_grad()\n",
    "    loss = get_loss(model, data, labels)\n",
    "    loss.backward()\n",
    "    return model.parameters()\n",
    "\n",
    "\n",
    "def get_acc(logits, labels):\n",
    "    predicted_labels = logits.argmax(dim=1)\n",
    "    return (predicted_labels == labels).float().mean().item()\n",
    "\n",
    "\n",
    "def train(model, x, y, lr=0.003, num_epochs=10):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    for _ in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        loss = get_loss(model, x, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "\n",
    "# Test\n",
    "mlp = MLP()\n",
    "rand_params = torch.randn(num_params) * 0.01\n",
    "mlp.fc1.weight.data = rand_params[:hidden_dim * input_dim].view(hidden_dim, input_dim)\n",
    "mlp.fc1.bias.data = rand_params[hidden_dim * input_dim:hidden_dim * input_dim + hidden_dim]\n",
    "mlp.fc2.weight.data = rand_params[-(output_dim * hidden_dim + output_dim):-output_dim].view(output_dim, hidden_dim)\n",
    "mlp.fc2.bias.data = rand_params[-output_dim:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UmazpzbAe5rr",
    "outputId": "e37ca022-ef6e-4c0a-b166-f78b9e2cca15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 64])\n",
      "Random MLP: loss=2.3013, acc=0.08\n",
      "mlp1 acc@d_odd=0.95\n",
      "mlp1 acc@d_even=0.00\n",
      "mlp1 acc@d0-9=0.48\n",
      "----------\n",
      "mlp2 acc@d_odd=0.00\n",
      "mlp2 acc@d_even=0.96\n",
      "mlp2 acc@d0-9=0.47\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "logits = mlp(images)\n",
    "loss = get_loss(mlp, images, labels)\n",
    "acc = get_acc(logits, labels)\n",
    "print(f'Random MLP: loss={loss.item():.4f}, acc={acc:.2f}')\n",
    "\n",
    "# Train 2 seed MLPs\n",
    "mlp1 = MLP()\n",
    "mlp2 = MLP()\n",
    "\n",
    "mlp1 = train(mlp1, odd_num_images, odd_num_labels)\n",
    "mlp2 = train(mlp2, even_num_images, even_num_labels)\n",
    "\n",
    "models = [mlp1, mlp2]\n",
    "model_names = ['mlp1', 'mlp2']\n",
    "for model, model_name in zip(models, model_names):\n",
    "    for x, y, name in zip([odd_num_images, even_num_images, images], [odd_num_labels, even_num_labels, labels], ['d_odd', 'd_even', 'd0-9']):\n",
    "        logits = model(x)\n",
    "        acc = get_acc(logits, y)\n",
    "        print(f'{model_name} acc@{name}={acc:.2f}')\n",
    "    print('-' * 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "6EVdBmBnfA2m",
    "outputId": "641b1c70-6d5e-418c-d1b0-0f9ac7a26e48"
   },
   "outputs": [],
   "source": [
    "class Slerp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Slerp, self).__init__()\n",
    "\n",
    "    \n",
    "    def forward(self, val, x, y):\n",
    "      norm_x = F.normalize(x, dim=-1)\n",
    "      norm_y = F.normalize(y, dim=-1)\n",
    "      dot = torch.sum(norm_x * norm_y, dim=-1, keepdim=True)\n",
    "      omega = torch.acos(torch.clamp(dot, -1.0, 1.0))\n",
    "      sin_omega = torch.sin(omega)\n",
    "      scale_x = torch.sin((1.0 - val) * omega) / sin_omega\n",
    "      scale_y = torch.sin(val * omega) / sin_omega\n",
    "      lin_scale_x = 1.0 - val\n",
    "      lin_scale_y = val\n",
    "      return torch.where(sin_omega > 1e-6, scale_x * x + scale_y * y, lin_scale_x * x + lin_scale_y * y)\n",
    "    '''\n",
    "    def forward(self, val, x, y):\n",
    "        return val*x + (1-val)*y\n",
    "    '''\n",
    "\n",
    "slerp = Slerp()\n",
    "\n",
    "RUN_FOLDER = './test_merge_dir/'\n",
    "\n",
    "from pathlib import Path\n",
    "Path(RUN_FOLDER).mkdir(parents=True, exist_ok=True) # create directory and any intermediate directories\n",
    "\n",
    "async def calibrate_operation(op_name, example_inputs, calibration_inputs, input_names, operation_fn, output_names):\n",
    "    model_path = os.path.join(RUN_FOLDER + op_name + '.onnx')\n",
    "    compiled_model_path = os.path.join(RUN_FOLDER + op_name + '_network.compiled')\n",
    "    pk_path = os.path.join(RUN_FOLDER + op_name + '_test.pk')\n",
    "    vk_path = os.path.join(RUN_FOLDER + op_name + '_test.vk')\n",
    "    settings_path = os.path.join(RUN_FOLDER + op_name + '_settings.json')\n",
    "    witness_path = os.path.join(RUN_FOLDER + op_name + '_calibration_witness.json')\n",
    "    data_path = os.path.join(RUN_FOLDER + op_name + '_calibration_input.json')\n",
    "\n",
    "    #import ipdb; ipdb.set_trace()\n",
    "    torch.onnx.export(\n",
    "        operation_fn,                       # the model/module to be exported\n",
    "        example_inputs,                 # example inputs\n",
    "        model_path,                # the file name to save the ONNX model\n",
    "        export_params=True,          # store the trained parameter weights inside the model file\n",
    "        opset_version=11,            # the ONNX version to export the model to\n",
    "        do_constant_folding=True,    # whether to execute constant folding for optimization\n",
    "        input_names=input_names,  # input names\n",
    "        output_names=output_names        # output name\n",
    "    )\n",
    "    \n",
    "    py_run_args = ezkl.PyRunArgs()\n",
    "    py_run_args.input_visibility = \"public\"\n",
    "    py_run_args.output_visibility = \"public\"\n",
    "    py_run_args.param_visibility = \"fixed\" # \"fixed\" for params means that the committed to params are used for all proofs\n",
    "\n",
    "    res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "\n",
    "    assert res == True\n",
    "    data = dict(input_data = calibration_inputs)\n",
    "    cal_path = os.path.join(RUN_FOLDER + op_name + \"_calibration.json\")\n",
    "\n",
    "    json.dump(data, open(cal_path, 'w'))\n",
    "\n",
    "    await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
    "\n",
    "    res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "    assert res == True\n",
    "\n",
    "    # srs path\n",
    "    #res = ezkl.get_srs(settings_path)\n",
    "    print(f'await get_srs({settings_path}')\n",
    "    res = await ezkl.get_srs(settings_path)\n",
    "    print(f'after await get_srs({settings_path}')\n",
    "    #res = await ezkl.get_srs(settings_path, commitment='ipa')\n",
    "    #res = await ezkl.get_srs(settings_path, commitment=ezkl.PyCommitments.IPA)\n",
    "    print(f'ezkl.setup({compiled_model_path},{vk_path},{pk_path}')\n",
    "    res = ezkl.setup(\n",
    "            compiled_model_path,\n",
    "            vk_path,\n",
    "            pk_path,\n",
    "        )\n",
    "    \n",
    "    assert res == True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 374
    },
    "id": "6EVdBmBnfA2m",
    "outputId": "641b1c70-6d5e-418c-d1b0-0f9ac7a26e48"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "value (2082345784286450043322368) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "value (2082345784286450043322368) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "value (2082345784286450043322368) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "value (2082345784286450043322368) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "value (2082345784286450043322368) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "value (2082345784286450043322368) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "value (7879442243890514531624943616) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "value (7879442243890514531624943616) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "value (7879442243890514531624943616) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "value (7879442243890514531624943616) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "Using 3 columns for non-linearity table.\n",
      "Using 3 columns for non-linearity table.\n",
      "Using 3 columns for non-linearity table.\n",
      "Using 3 columns for non-linearity table.\n",
      "Using 3 columns for non-linearity table.\n",
      "Using 3 columns for non-linearity table.\n",
      "Using 3 columns for non-linearity table.\n",
      "Using 3 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 5 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 2 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "value (31886212634194880129232875290624) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "value (31886212634194880129232875290624) out of range: (0, 0)\n",
      "forward pass failed: \"failed to forward: [halo2] General synthesis error\"\n",
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 13, param_scale: 13, scale_input_multiplier: 1) ------------->\n",
      "\n",
      "+--------------+--------------+---------------+--------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error   | median_error | max_error     | min_error    | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+--------------+--------------+---------------+--------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| -0.017569372 | -0.027148008 | 0.00008401123 | -0.034992814 | 0.017569385    | 0.027148008      | 0.034992814   | 0.00002800906 | 0.00036208806      | -0.036453556       | 0.036464002            |\n",
      "+--------------+--------------+---------------+--------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "await get_srs(./test_merge_dir/merge_settings.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the elites with seed models\n",
    "mlp1_param = torch.concatenate([mlp1.state_dict()['fc1.weight'].view(-1), mlp1.state_dict()['fc1.bias'].view(-1), mlp1.state_dict()['fc2.weight'].view(-1), mlp1.state_dict()['fc2.bias'].view(-1)])\n",
    "mlp2_param = torch.concatenate([mlp2.state_dict()['fc1.weight'].view(-1), mlp2.state_dict()['fc1.bias'].view(-1), mlp2.state_dict()['fc2.weight'].view(-1), mlp2.state_dict()['fc2.bias'].view(-1)])\n",
    "elites = torch.stack([mlp1_param, mlp2_param])\n",
    "#elites = elites[torch.randint(0, 2, (num_elite,))]\n",
    "\n",
    "# calibrate circuit\n",
    "val = torch.rand(1)\n",
    "loop = asyncio.get_event_loop()\n",
    "calibrate_start = time.time()\n",
    "#verified = loop.run_until_complete(calibrate_circuit(val, mlp1_param, mlp2_param))\n",
    "\n",
    "op_name = 'merge'\n",
    "example_inputs = (val, mlp1_param, mlp2_param)\n",
    "calibration_inputs = [[val.item()], \n",
    "                              torch.rand(*mlp1_param.shape).detach().numpy().reshape(-1).tolist(), \n",
    "                              torch.rand(*mlp2_param.shape).detach().numpy().reshape(-1).tolist()]\n",
    "input_names = ['val', 'parent_1', 'parent_2']  # input names\n",
    "operation_fn = slerp\n",
    "output_names = ['merged_weights']        # output name\n",
    "\n",
    "loop.run_until_complete(calibrate_operation(op_name, example_inputs, calibration_inputs, input_names, operation_fn, output_names))\n",
    "\n",
    "calibrate_end = time.time()\n",
    "calibration_duration = calibrate_end - calibrate_start\n",
    "print('Calibration duration: ' + str(calibration_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 1, 1)]\n",
      "Model 1 from iteration 4 has parents 1 and 1 from iteration 3\n",
      "Iteration 4\n",
      "{(1, 0, 1)}\n",
      "number of parents to verify 1\n",
      "{(1, 0, 1)}\n",
      "Model 1 from iteration 3 has parents 0 and 1 from iteration 2\n",
      "Iteration 3\n",
      "{(1, 0, 0), (0, 3, 0)}\n",
      "number of parents to verify 2\n",
      "{(1, 0, 0), (0, 3, 0)}\n",
      "Model 1 from iteration 2 has parents 0 and 0 from iteration 1\n",
      "{(1, 0, 0), (0, 3, 0)}\n",
      "Model 0 from iteration 2 has parents 3 and 0 from iteration 1\n",
      "Iteration 2\n",
      "{(3, 3, 1), (0, 1, 1)}\n",
      "number of parents to verify 2\n",
      "{(3, 3, 1), (0, 1, 1)}\n",
      "Model 3 from iteration 1 has parents 3 and 1 from iteration 0\n",
      "{(3, 3, 1), (0, 1, 1)}\n",
      "Model 0 from iteration 1 has parents 1 and 1 from iteration 0\n",
      "Iteration 1\n",
      "{(3, 1, 0), (1, 1, 0)}\n",
      "number of parents to verify 2\n",
      "{(3, 1, 0), (1, 1, 0)}\n",
      "Model 3 from iteration 0 has parents 1 and 0 from iteration -1\n",
      "{(3, 1, 0), (1, 1, 0)}\n",
      "Model 1 from iteration 0 has parents 1 and 0 from iteration -1\n",
      "Iteration 0\n",
      "{(0, 3, 2), (1, 1, 1)}\n",
      "number of parents to verify 2\n",
      "Aggregating ./test_merge_dir/iter_4_merge_idx_1_p1_1_p2_1_test.pf and ./test_merge_dir/iter_4_merge_idx_1_mutate_test.pf ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "thread '<unnamed>' panicked at /root/.cargo/git/checkouts/halo2-9de98af521c882c2/8cfca22/halo2_proofs/src/dev.rs:457:13:\n",
      "row=2097146, usable_rows=0..2097146, k=21\n",
      "stack backtrace:\n",
      "   0:     0x7c3295b8c925 - <std::sys::backtrace::BacktraceLock::print::DisplayBacktrace as core::fmt::Display>::fmt::hca750ad87bb2f1d4\n",
      "   1:     0x7c3295bbae9b - core::fmt::write::h133a0eb20f0a6a5d\n",
      "   2:     0x7c3295b887ef - std::io::Write::write_fmt::h0b1c7497ddea4e96\n",
      "   3:     0x7c3295b8dca1 - std::panicking::default_hook::{{closure}}::h7dd45b5804215332\n",
      "   4:     0x7c3295b8d97c - std::panicking::default_hook::haed8ee3169af9669\n",
      "   5:     0x7c3295b8e371 - std::panicking::rust_panic_with_hook::h4bf66cb658082ab2\n",
      "   6:     0x7c3295b8e1d7 - std::panicking::begin_panic_handler::{{closure}}::h7a19fc32e0e387d7\n",
      "   7:     0x7c3295b8cde9 - std::sys::backtrace::__rust_end_short_backtrace::h6117389318248cc0\n",
      "   8:     0x7c3295b8de64 - rust_begin_unwind\n",
      "   9:     0x7c3295bb7e13 - core::panicking::panic_fmt::h1817a57f977b857c\n",
      "  10:     0x7c329465e8e0 - <halo2_proofs::dev::MockProver<F> as halo2_proofs::plonk::circuit::Assignment<F>>::assign_advice::h2380b3571234dcb3\n",
      "  11:     0x7c329487158f - <halo2_proofs::circuit::floor_planner::single_pass::SingleChipLayouterRegion<F,CS> as halo2_proofs::circuit::layouter::RegionLayouter<F>>::assign_advice::h2d8deb51fa0b26da\n",
      "  12:     0x7c32941b7140 - <core::iter::adapters::map::Map<I,F> as core::iter::traits::iterator::Iterator>::try_fold::hc2b5789dda0bb855\n",
      "  13:     0x7c329407d750 - <alloc::vec::Vec<T> as alloc::vec::spec_from_iter::SpecFromIter<T,I>>::from_iter::hef41b7dcfb7311e2\n",
      "  14:     0x7c3294853921 - <maingate::main_gate::MainGate<F> as maingate::instructions::MainGateInstructions<F,_>>::apply::h419362622daf61b8\n",
      "  15:     0x7c3294895ef6 - maingate::instructions::MainGateInstructions::compose::hde0c6f6bac15047f\n",
      "  16:     0x7c329486d162 - snark_verifier::loader::halo2::shim::halo2_wrong::<impl snark_verifier::loader::halo2::shim::IntegerInstructions<F> for maingate::main_gate::MainGate<F>>::sum_with_coeff_and_const::h86d28e26878d0079\n",
      "  17:     0x7c32943d42ce - snark_verifier::loader::halo2::loader::<impl snark_verifier::loader::ScalarLoader<<C as group::prime::PrimeCurveAffine>::Scalar> for alloc::rc::Rc<snark_verifier::loader::halo2::loader::Halo2Loader<C,EccChip>>>::sum_with_coeff_and_const::hc5ec97b3d5c0b18c\n",
      "  18:     0x7c329405875b - <alloc::vec::Vec<T> as alloc::vec::spec_from_iter::SpecFromIter<T,I>>::from_iter::h7e452c182e806b16\n",
      "  19:     0x7c32943d1003 - snark_verifier::util::hash::poseidon::Poseidon<F,L,_,_>::permutation::h9a1112c0cbcc12ea\n",
      "  20:     0x7c32943d2d08 - snark_verifier::util::hash::poseidon::Poseidon<F,L,_,_>::squeeze::ha563cf28ab2be8ac\n",
      "  21:     0x7c329406a70b - <alloc::vec::Vec<T> as alloc::vec::spec_from_iter::SpecFromIter<T,I>>::from_iter::hb3934c0277818d39\n",
      "  22:     0x7c32941b7c0a - <core::iter::adapters::map::Map<I,F> as core::iter::traits::iterator::Iterator>::try_fold::hc49d3a0da79c571f\n",
      "  23:     0x7c329402fc04 - <alloc::vec::Vec<T> as alloc::vec::spec_from_iter::SpecFromIter<T,I>>::from_iter::h044d92c308e4b474\n",
      "  24:     0x7c32942d2731 - core::iter::adapters::try_process::h549a42a29de2fb48\n",
      "  25:     0x7c32943db7e7 - snark_verifier::verifier::plonk::proof::PlonkProof<C,L,AS>::read::hf3738dedb9c0f002\n",
      "  26:     0x7c32944e84bb - ezkl::pfsys::evm::aggregation_kzg::aggregate::hdf557fa7fa32714f\n",
      "  27:     0x7c32948a0092 - <ezkl::pfsys::evm::aggregation_kzg::AggregationCircuit as halo2_proofs::plonk::circuit::Circuit<halo2curves::bn256::fr::Fr>>::synthesize::{{closure}}::h00de57f2a8657048\n",
      "  28:     0x7c3294869b1c - <halo2_proofs::circuit::floor_planner::single_pass::SingleChipLayouter<F,CS> as halo2_proofs::circuit::Layouter<F>>::assign_region::hc06e8db4ec0b300f\n",
      "  29:     0x7c32944eb990 - <ezkl::pfsys::evm::aggregation_kzg::AggregationCircuit as halo2_proofs::plonk::circuit::Circuit<halo2curves::bn256::fr::Fr>>::synthesize::h660856dc274efd74\n",
      "  30:     0x7c3294865c94 - <halo2_proofs::circuit::floor_planner::single_pass::SimpleFloorPlanner as halo2_proofs::plonk::circuit::FloorPlanner>::synthesize::hf866d52de9270ea0\n",
      "  31:     0x7c3294664066 - halo2_proofs::dev::MockProver<F>::run::h82aaed8b88cd5490\n",
      "  32:     0x7c329483197e - ezkl::execute::mock_aggregate::h7cf7b8f7eea35587\n",
      "  33:     0x7c329436ac40 - ezkl::python::__pyfunction_mock_aggregate::h581be758fc902276\n",
      "  34:     0x7c329432abcc - pyo3::impl_::trampoline::trampoline::h1053cb102fd6c25c\n",
      "  35:     0x7c329436a881 - ezkl::python::<impl ezkl::python::mock_aggregate::MakeDef>::_PYO3_DEF::trampoline::h3490552b003e53a9\n",
      "  36:     0x7c33e7bb0a87 - <unknown>\n",
      "  37:     0x7c33e7b80abb - _PyObject_MakeTpCall\n",
      "  38:     0x7c33e7b8931f - _PyEval_EvalFrameDefault\n",
      "  39:     0x7c33e7c63baa - <unknown>\n",
      "  40:     0x7c33e7cbaf0c - <unknown>\n",
      "  41:     0x7c33e7b8d219 - _PyEval_EvalFrameDefault\n",
      "  42:     0x7c33e7be166c - <unknown>\n",
      "  43:     0x7c33e7cea8ff - <unknown>\n",
      "  44:     0x7c33e7b42515 - <unknown>\n",
      "  45:     0x7c33e7ba4cbe - <unknown>\n",
      "  46:     0x7c33e7b8e71b - _PyEval_EvalFrameDefault\n",
      "  47:     0x7c33e7c4d0f5 - PyEval_EvalCode\n",
      "  48:     0x7c33e7c68706 - <unknown>\n",
      "  49:     0x7c33e7ba4cbe - <unknown>\n",
      "  50:     0x7c33e7ba4b6d - PyObject_Vectorcall\n",
      "  51:     0x7c33e7b8931f - _PyEval_EvalFrameDefault\n",
      "  52:     0x7c33e7c7d55f - <unknown>\n",
      "  53:     0x7c33e7c7ce06 - Py_RunMain\n",
      "  54:     0x7c33e7c3860c - Py_BytesMain\n",
      "  55:     0x7c33e7834e08 - <unknown>\n",
      "  56:     0x7c33e7834ecc - __libc_start_main\n",
      "  57:     0x55dde6a2f045 - _start\n",
      "  58:                0x0 - <unknown>\n"
     ]
    },
    {
     "ename": "PanicException",
     "evalue": "row=2097146, usable_rows=0..2097146, k=21",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPanicException\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m verify_start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      2\u001b[0m best_ind \u001b[38;5;241m=\u001b[39m top_inds[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m verify_only_best_path_proofs(merge_idx_and_p_inds, best_ind)\n\u001b[1;32m      4\u001b[0m verify_end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      6\u001b[0m verify_duration \u001b[38;5;241m=\u001b[39m verify_end \u001b[38;5;241m-\u001b[39m verify_start\n",
      "Cell \u001b[0;32mIn[10], line 120\u001b[0m, in \u001b[0;36mverify_only_best_path_proofs\u001b[0;34m(merge_idx_and_p_inds, best_ind)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumber of parents to verify \u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mlen\u001b[39m(parents_to_verify)))\n\u001b[1;32m    118\u001b[0m \u001b[38;5;66;03m#return await asyncio.gather(*(verify_proofs(merge_id) for merge_id in merge_ids))\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;66;03m#await asyncio.gather(*(aggregate_merge_and_mutate(merge_id, mutate_id) for (merge_id, mutate_id) in all_ids))\u001b[39;00m\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mawait\u001b[39;00m aggregate_merge_and_mutate(\u001b[38;5;241m*\u001b[39m(\u001b[38;5;28mlist\u001b[39m(all_ids)[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m*\u001b[39m(verify_proofs(merge_id, mutate_id) \u001b[38;5;28;01mfor\u001b[39;00m (merge_id, mutate_id) \u001b[38;5;129;01min\u001b[39;00m all_ids))\n",
      "Cell \u001b[0;32mIn[10], line 37\u001b[0m, in \u001b[0;36maggregate_merge_and_mutate\u001b[0;34m(merge_id, mutate_id)\u001b[0m\n\u001b[1;32m     35\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m ezkl\u001b[38;5;241m.\u001b[39mget_srs(settings_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, logrows\u001b[38;5;241m=\u001b[39mnum_logrows, commitment\u001b[38;5;241m=\u001b[39mezkl\u001b[38;5;241m.\u001b[39mPyCommitments\u001b[38;5;241m.\u001b[39mKZG)\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m#res = ezkl.mock_aggregate([merge_proof_path, mutate_proof_path], num_logrows)\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mezkl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmock_aggregate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmerge_proof_path\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_logrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mipdb\u001b[39;00m; ipdb\u001b[38;5;241m.\u001b[39mset_trace()\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mPanicException\u001b[0m: row=2097146, usable_rows=0..2097146, k=21"
     ]
    }
   ],
   "source": [
    "verify_start = time.time()\n",
    "best_ind = top_inds[0]\n",
    "await verify_only_best_path_proofs(merge_idx_and_p_inds, best_ind)\n",
    "verify_end = time.time()\n",
    "\n",
    "verify_duration = verify_end - verify_start\n",
    "print('Proof verification duration (best path):' + str(verify_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 7 columns for non-linearity table.\n",
      "Using 7 columns for non-linearity table.\n",
      "Using 7 columns for non-linearity table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64])\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 7 columns for non-linearity table.\n",
      "Using 7 columns for non-linearity table.\n",
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 11, param_scale: 11, scale_input_multiplier: 1) ------------->\n",
      "\n",
      "+----------------+----------------+----------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error     | median_error   | max_error      | min_error      | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+----------------+----------------+----------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| -0.00048828125 | -0.00048828125 | -0.00048828125 | -0.00048828125 | 0.00048828125  | 0.00048828125    | 0.00048828125 | 0.00048828125 | 0.00000023841858   | -0.00048828125     | 0.00048828125          |\n",
      "+----------------+----------------+----------------+----------------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## EVALUATION\n",
    "batch_size = 3\n",
    "\n",
    "class EvaluateModel(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        # self.X = X\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, X, y):\n",
    "        logits = self.model(X)\n",
    "        return get_acc(logits, y)\n",
    "\n",
    "def get_acc(logits, labels):\n",
    "    predicted_labels = logits.argmax(dim=-1)\n",
    "    return (predicted_labels == labels).float().mean()\n",
    "\n",
    "best_model = reroll_params(elites[0])\n",
    "eval_mod = EvaluateModel(best_model)\n",
    "RUN_FOLDER = \"./test_eval_dir/\"\n",
    "\n",
    "from pathlib import Path\n",
    "Path(RUN_FOLDER).mkdir(parents=True, exist_ok=True) # create directory and any intermediate directories\n",
    "\n",
    "\n",
    "images = images[:batch_size, :]\n",
    "labels = labels[:batch_size]\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "op_name = 'eval'\n",
    "example_inputs = (images, labels)\n",
    "calibration_inputs = [images.detach().numpy().reshape(-1).tolist(),\n",
    "                       labels.detach().numpy().reshape(-1).tolist()]\n",
    "input_names = ['images', 'labels']\n",
    "output_names = ['acc']\n",
    "\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(calibrate_operation(op_name, example_inputs, calibration_inputs, input_names, eval_mod, output_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
