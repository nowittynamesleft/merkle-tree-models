{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 8 columns for non-linearity table.\n",
      "Using 8 columns for non-linearity table.\n",
      "Using 8 columns for non-linearity table.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_params=19210\n",
      "torch.Size([3, 64])\n",
      "torch.Size([3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 4 columns for non-linearity table.\n",
      "Using 4 columns for non-linearity table.\n",
      "Using 8 columns for non-linearity table.\n",
      "Using 8 columns for non-linearity table.\n",
      "\n",
      "\n",
      " <------------- Numerical Fidelity Report (input_scale: 11, param_scale: 11, scale_input_multiplier: 1) ------------->\n",
      "\n",
      "+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| mean_error | median_error | max_error | min_error | mean_abs_error | median_abs_error | max_abs_error | min_abs_error | mean_squared_error | mean_percent_error | mean_abs_percent_error |\n",
      "+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "| 0          | 0            | 0         | 0         | 0              | 0                | 0             | 0             | 0                  | 0                  | 0                      |\n",
      "+------------+--------------+-----------+-----------+----------------+------------------+---------------+---------------+--------------------+--------------------+------------------------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibration duration: 2.7758753299713135\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import asyncio\n",
    "from sklearn import datasets\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "import tqdm\n",
    "\n",
    "import ezkl\n",
    "import os\n",
    "\n",
    "\n",
    "images, labels = datasets.load_digits(return_X_y=True)\n",
    "images = torch.tensor(images, dtype=torch.float32)\n",
    "labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "\n",
    "hidden_dim = 256\n",
    "input_dim = 64\n",
    "output_dim = 10\n",
    "num_params = (1 + input_dim) * hidden_dim + (1 + hidden_dim) * output_dim\n",
    "\n",
    "batch_size = 3\n",
    "print(f'num_params={num_params}')\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class EvaluateModel(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        # self.X = X\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, X, y):\n",
    "        logits = self.model(X)\n",
    "        return get_acc(logits, y)\n",
    "\n",
    "def get_acc(logits, labels):\n",
    "    predicted_labels = logits.argmax(dim=-1)\n",
    "    return (predicted_labels == labels).float().mean()\n",
    "\n",
    "mlp = MLP()\n",
    "eval_mod = EvaluateModel(mlp)\n",
    "RUN_FOLDER = \"./test_eval_dir/\"\n",
    "\n",
    "from pathlib import Path\n",
    "Path(RUN_FOLDER).mkdir(parents=True, exist_ok=True) # create directory and any intermediate directories\n",
    "\n",
    "model_path = os.path.join(RUN_FOLDER + 'eval.onnx')\n",
    "compiled_model_path = os.path.join(RUN_FOLDER + 'eval_network.compiled')\n",
    "pk_path = os.path.join(RUN_FOLDER + 'test.pk')\n",
    "vk_path = os.path.join(RUN_FOLDER + 'test.vk')\n",
    "settings_path = os.path.join(RUN_FOLDER + 'settings.json')                                            \n",
    "                                                                                                               \n",
    "witness_path = os.path.join(RUN_FOLDER + 'witness.json')                                              \n",
    "                                                                                                               \n",
    "data_path = os.path.join(RUN_FOLDER + 'test_input.json')    \n",
    "images = images[:batch_size, :]\n",
    "labels = labels[:batch_size]\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "eval_mod = torch.jit.script(eval_mod)\n",
    "\n",
    "torch.onnx.export(\n",
    "    eval_mod,                       # the model/module to be exported\n",
    "    (images, labels),                 # example inputs\n",
    "    model_path,                # the file name to save the ONNX model\n",
    "    export_params=True,          # store the trained parameter weights inside the model file\n",
    "    opset_version=11,            # the ONNX version to export the model to\n",
    "    do_constant_folding=True,    # whether to execute constant folding for optimization\n",
    "    input_names=['images', 'labels'],  # input names\n",
    "    output_names=['acc']        # output name\n",
    ")\n",
    "\n",
    "py_run_args = ezkl.PyRunArgs()\n",
    "py_run_args.input_visibility = \"public\"\n",
    "py_run_args.output_visibility = \"public\"\n",
    "py_run_args.param_visibility = \"fixed\"\n",
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "cal_path = os.path.join(RUN_FOLDER + \"calibration.json\")\n",
    "# data = dict(input_data = [torch.rand(*images.shape).detach().numpy().reshape(-1).tolist(),\n",
    "#                          torch.rand(*labels.shape).detach().numpy().reshape(-1).tolist()])\n",
    "data = dict(input_data = [images.detach().numpy().reshape(-1).tolist(),\n",
    "                       labels.detach().numpy().reshape(-1).tolist()])\n",
    "\n",
    "\n",
    "json.dump(data, open(cal_path, 'w'))\n",
    "# calibrate\n",
    "start_cal = time.time()\n",
    "await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
    "end_cal = time.time()\n",
    "cal_dur = end_cal - start_cal\n",
    "print('Calibration duration: ' + str(cal_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Circuit compilation duration: 0.008025169372558594\n",
      "SRS duration: 0.015050888061523438\n"
     ]
    }
   ],
   "source": [
    "start_comp = time.time()\n",
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "end_comp = time.time()\n",
    "comp_dur = end_comp - start_comp\n",
    "print('Circuit compilation duration: ' + str(comp_dur))\n",
    "\n",
    "assert res == True\n",
    "\n",
    "srs_start = time.time()\n",
    "res = await ezkl.get_srs( settings_path)\n",
    "assert res == True\n",
    "srs_end = time.time()\n",
    "srs_dur = srs_end - srs_start\n",
    "print('SRS duration: ' + str(srs_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64])\n",
      "torch.Size([3])\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re init paths\n",
    "# merge_id = 'iter_' + str(iteration) + '_merge_idx_' + str(merge_idx) + '_p1_' + str(parent_id_1.item()) + '_p2_' + str(parent_id_2.item())\n",
    "# model_path = os.path.join(RUN_FOLDER + 'slerp.onnx')\n",
    "# compiled_model_path = os.path.join(RUN_FOLDER + 'network.compiled')\n",
    "# pk_path = os.path.join(RUN_FOLDER + merge_id + '_test.pk')\n",
    "# vk_path = os.path.join(RUN_FOLDER + merge_id + '_test.vk')\n",
    "# settings_path = os.path.join(RUN_FOLDER + 'settings.json')\n",
    "\n",
    "# witness_path = os.path.join(RUN_FOLDER + 'witness.json')\n",
    "# data_path = os.path.join(RUN_FOLDER + 'slerp_input_' + merge_id + '.json')\n",
    "model_path = os.path.join(RUN_FOLDER + 'eval.onnx')\n",
    "compiled_model_path = os.path.join(RUN_FOLDER + 'eval_network.compiled')\n",
    "pk_path = os.path.join(RUN_FOLDER + 'test.pk')\n",
    "vk_path = os.path.join(RUN_FOLDER + 'test.vk')\n",
    "settings_path = os.path.join(RUN_FOLDER + 'settings.json')                                            \n",
    "                                                                                                               \n",
    "                                                                                                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1797, 64])\n",
      "torch.Size([1797])\n",
      "Proof setup duration: 6.927207946777344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                      | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Witness duration: 0.05954289436340332\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|███████████████████████▌                                                                      | 1/4 [00:11<00:33, 11.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proof duration: 11.245236873626709\n",
      "Witness duration: 0.03202199935913086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|███████████████████████████████████████████████                                               | 2/4 [00:22<00:22, 11.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proof duration: 11.219467401504517\n",
      "Witness duration: 0.04000139236450195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|██████████████████████████████████████████████████████████████████████▌                       | 3/4 [00:33<00:11, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proof duration: 11.389256715774536\n",
      "Witness duration: 0.04317736625671387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:45<00:00, 11.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proof duration: 11.365727663040161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get test input\n",
    "images, labels = datasets.load_digits(return_X_y=True)\n",
    "images = torch.tensor(images, dtype=torch.float32)\n",
    "labels = torch.tensor(labels, dtype=torch.int64)\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "total_chunks = images.shape[0] // batch_size # assumes divisible\n",
    "proof_setup_start = time.time()\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)\n",
    "\n",
    "proof_setup_end = time.time()\n",
    "proof_setup_dur = proof_setup_end - proof_setup_start\n",
    "print('Proof setup duration: ' + str(proof_setup_dur))\n",
    "\n",
    "#total_chunks = 4 # for testing\n",
    "for i in tqdm.tqdm(range(total_chunks)):\n",
    "\n",
    "    witness_path = os.path.join(RUN_FOLDER + f'witness_{i}.json')                                              \n",
    "    data = dict(input_data = [images[i * batch_size: (i + 1) * batch_size, :].detach().numpy().reshape(-1).tolist(),\n",
    "                        labels[i * batch_size: (i + 1) * batch_size].detach().numpy().reshape(-1).tolist()])\n",
    "\n",
    "\n",
    "    data_path = os.path.join(RUN_FOLDER + f'actual_test_input_{i}.json')\n",
    "    with open(data_path, \"w\") as f:\n",
    "        json.dump(data, f)\n",
    "\n",
    "    witness_start = time.time()\n",
    "    res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "    assert os.path.isfile(witness_path)\n",
    "    witness_end = time.time()\n",
    "    witness_dur = witness_end - witness_start\n",
    "    print('Witness duration: ' + str(witness_dur))\n",
    "\n",
    "\n",
    "    proof_path = os.path.join(RUN_FOLDER + f\"test_proof_{i}.pf\")\n",
    "    proof_start = time.time()\n",
    "    # prove\n",
    "    res = ezkl.prove(\n",
    "            witness_path,\n",
    "            compiled_model_path,\n",
    "            pk_path,\n",
    "            proof_path,\n",
    "\n",
    "            \"single\",\n",
    "        )\n",
    "\n",
    "    #print(res)\n",
    "    proof_end = time.time()\n",
    "    proof_duration = proof_end - proof_start\n",
    "    print('Proof duration: ' + str(proof_duration))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "verified\n",
      "verified\n",
      "verified\n",
      "verified\n",
      "Total verify duration: 0.07295751571655273\n"
     ]
    }
   ],
   "source": [
    "# verify generated proofs\n",
    "start_verify = time.time()\n",
    "for i in range(total_chunks):\n",
    "    witness_path = os.path.join(RUN_FOLDER + f'witness_{i}.json')\n",
    "    proof_path = os.path.join(RUN_FOLDER + f\"test_proof_{i}.pf\")\n",
    "    res = ezkl.verify(\n",
    "            proof_path,\n",
    "            settings_path,\n",
    "            vk_path\n",
    "        )\n",
    "    assert res == True\n",
    "    print(\"verified\")\n",
    "    \n",
    "end_verify = time.time()\n",
    "verify_dur = end_verify - start_verify\n",
    "print('Total verify duration: ' + str(verify_dur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate witness\n",
    "'''\n",
    "witness_start = time.time()\n",
    "res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "assert os.path.isfile(witness_path)\n",
    "witness_end = time.time()\n",
    "witness_dur = witness_end - witness_start\n",
    "print('Witness duration: ' + str(witness_dur))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# setup proof\n",
    "proof_setup_start = time.time()\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)\n",
    "\n",
    "proof_setup_end = time.time()\n",
    "proof_setup_dur = proof_setup_end - proof_setup_start\n",
    "print('Proof setup duration: ' + str(proof_setup_dur))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "proof_path = os.path.join(RUN_FOLDER + \"test_proof.pf\")\n",
    "proof_start = time.time()\n",
    "# prove\n",
    "res = ezkl.prove(\n",
    "        witness_path,\n",
    "        compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "\n",
    "        \"single\",\n",
    "    )\n",
    "\n",
    "print(res)\n",
    "proof_end = time.time()\n",
    "proof_duration = proof_end - proof_start\n",
    "print('Proof duration: ' + str(proof_duration))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
