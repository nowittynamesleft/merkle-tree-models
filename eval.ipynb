{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import asyncio\n",
    "from sklearn import datasets\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import time\n",
    "\n",
    "import ezkl\n",
    "import os\n",
    "\n",
    "\n",
    "images, labels = datasets.load_digits(return_X_y=True)\n",
    "images = torch.tensor(images, dtype=torch.float32)\n",
    "labels = torch.tensor(labels, dtype=torch.int64)\n",
    "\n",
    "\n",
    "hidden_dim = 256\n",
    "input_dim = 64\n",
    "output_dim = 10\n",
    "num_params = (1 + input_dim) * hidden_dim + (1 + hidden_dim) * output_dim\n",
    "print(f'num_params={num_params}')\n",
    "\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class EvaluateModel(nn.Module):\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        # self.X = X\n",
    "        self.model = model\n",
    "    \n",
    "    def forward(self, X, y):\n",
    "        logits = self.model(X)\n",
    "        return get_acc(logits, y)\n",
    "\n",
    "def get_acc(logits, labels):\n",
    "    predicted_labels = logits.argmax(dim=1)\n",
    "    return (predicted_labels == labels).float().mean()\n",
    "\n",
    "mlp = MLP()\n",
    "eval_mod = EvaluateModel(mlp)\n",
    "images = images[:2, :]\n",
    "labels = labels[:2]\n",
    "\n",
    "RUN_FOLDER = \"./\"\n",
    "model_path = os.path.join(RUN_FOLDER + 'eval.onnx')\n",
    "compiled_model_path = os.path.join(RUN_FOLDER + 'eval_network.compiled')\n",
    "pk_path = os.path.join(RUN_FOLDER + 'test.pk')\n",
    "vk_path = os.path.join(RUN_FOLDER + 'test.vk')\n",
    "settings_path = os.path.join(RUN_FOLDER + 'settings.json')                                            \n",
    "                                                                                                               \n",
    "witness_path = os.path.join(RUN_FOLDER + 'witness.json')                                              \n",
    "                                                                                                               \n",
    "data_path = os.path.join(RUN_FOLDER + 'test_input.json')                                              \n",
    "torch.onnx.export(\n",
    "    eval_mod,                       # the model/module to be exported\n",
    "    (images, labels),                 # example inputs\n",
    "    model_path,                # the file name to save the ONNX model\n",
    "    export_params=True,          # store the trained parameter weights inside the model file\n",
    "    opset_version=11,            # the ONNX version to export the model to\n",
    "    do_constant_folding=True,    # whether to execute constant folding for optimization\n",
    "    input_names=['images', 'labels'],  # input names\n",
    "    output_names=['acc']        # output name\n",
    ")\n",
    "\n",
    "py_run_args = ezkl.PyRunArgs()\n",
    "py_run_args.input_visibility = \"public\"\n",
    "py_run_args.output_visibility = \"public\"\n",
    "py_run_args.param_visibility = \"fixed\"\n",
    "res = ezkl.gen_settings(model_path, settings_path, py_run_args=py_run_args)\n",
    "cal_path = os.path.join(RUN_FOLDER + \"calibration.json\")\n",
    "data = dict(input_data = [torch.rand(*images.shape).detach().numpy().reshape(-1).tolist(),\n",
    "                         torch.rand(*labels.shape).detach().numpy().reshape(-1).tolist()])\n",
    "\n",
    "json.dump(data, open(cal_path, 'w'))\n",
    "await ezkl.calibrate_settings(cal_path, model_path, settings_path, \"resources\")\n",
    "res = ezkl.compile_circuit(model_path, compiled_model_path, settings_path)\n",
    "assert res == True\n",
    "\n",
    "res = await ezkl.get_srs( settings_path)\n",
    "asseert res == True\n",
    "\n",
    "\n",
    "data = dict(input_data = [images.detach().numpy().reshape(-1).tolist(),\n",
    "                       labels.detach().numpy().reshape(-1).tolist()])\n",
    "\n",
    "data_path = os.path.join(RUN_FOLDER + 'actual_test_input.json')\n",
    "with open(data_path, \"w\") as f:\n",
    "    json.dump(data, f)\n",
    "\n",
    "\n",
    "res = await ezkl.gen_witness(data_path, compiled_model_path, witness_path)\n",
    "assert res == True\n",
    "assert os.path.isfile(witness_path)\n",
    "\n",
    "res = ezkl.setup(\n",
    "        compiled_model_path,\n",
    "        vk_path,\n",
    "        pk_path,\n",
    "    )\n",
    "\n",
    "assert res == True\n",
    "assert os.path.isfile(vk_path)\n",
    "assert os.path.isfile(pk_path)\n",
    "assert os.path.isfile(settings_path)\n",
    "\n",
    "proof_path = os.path.join(RUN_FOLDER + \"test_proof.pf\")\n",
    "res = ezkl.prove(\n",
    "        witness_path,\n",
    "        compiled_model_path,\n",
    "        pk_path,\n",
    "        proof_path,\n",
    "\n",
    "        \"single\",\n",
    "    )\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
